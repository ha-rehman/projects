{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mxnet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-7f5013b30efa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# import d2lzh as d2l\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmxnet\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmxnet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgluon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmxnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgluon\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmxnet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mautograd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mxnet'"
     ]
    }
   ],
   "source": [
    "import d2lzh as d2l\n",
    "import mxnet as mx\n",
    "from mxnet import gluon, init\n",
    "from mxnet.gluon import loss as gloss\n",
    "from mxnet import autograd, nd\n",
    "from mxnet import nd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mxnet.io import ImageRecordIter\n",
    "import os, time, shutil \n",
    "from mxnet import autograd as ag\n",
    "from mxnet.gluon import nn\n",
    "from mxnet.gluon.data.vision import transforms\n",
    "from gluoncv.utils import makedirs\n",
    "from gluoncv.model_zoo import get_model\n",
    "from mxnet.gluon import data as gdata, loss as gloss, utils as gutils\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The structure of the modified mobilenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'mobilenetv3_small'\n",
    "classes = 5\n",
    "finetune_net = get_model(model_name, pretrained=True)\n",
    "\n",
    "def conv_block(num_channels):\n",
    "    blk = nn.HybridSequential() \n",
    "    blk.add(nn.Conv2D(num_channels,(1,1)),\n",
    "            nn.BatchNorm(),\n",
    "            nn.Activation('relu'),\n",
    "            nn.GlobalAvgPool2D())\n",
    "    return blk\n",
    "\n",
    "class modifiedMobileNet(nn.HybridBlock):\n",
    "  \n",
    "    def __init__(self, **kwargs):\n",
    "        super(modifiedMobileNet, self).__init__(**kwargs)\n",
    "        finetune_net = get_model(model_name, pretrained=True)\n",
    "        with self.name_scope():\n",
    "          self.part1 = finetune_net.features[:3]\n",
    "          self.part2 = finetune_net.features[3]\n",
    "          self.part3 = finetune_net.features[4]\n",
    "          self.part4 = finetune_net.features[5]\n",
    "          self.part5 = finetune_net.features[6:21]\n",
    "          self.part6 = nn.Dense(classes)\n",
    "         # self.part6 = nn.Conv2D(classes, kernel_size=(1, 1))\n",
    "          self.flatten = nn.Flatten()\n",
    "          self.dropout = nn.Dropout(0.5)\n",
    "          self.conv1 = conv_block(64)\n",
    "          self.conv2 = conv_block(64)\n",
    "          self.conv3 = conv_block(64)\n",
    "          self.conv4 = conv_block(64)\n",
    "          self.conv5 = conv_block(64)\n",
    "          self.w = conv_block(5)\n",
    "     \n",
    "\n",
    "    def forward(self,x):\n",
    "            w = self.w(x)\n",
    "            w = self.flatten(w)\n",
    "       #     print(w.shape)\n",
    "            x = self.part1(x)\n",
    "            x1 = self.conv1(x)\n",
    "       #     print(x1.shape)\n",
    "            x = self.part2(x)\n",
    "            x2 = self.conv2(x)\n",
    "       #     print(x2.shape)\n",
    "            x = self.part3(x)\n",
    "            x3 = self.conv3(x)\n",
    "      #      print(x3.shape)\n",
    "            x = self.part4(x)\n",
    "            x4 = self.conv4(x)\n",
    "      #      print(x4.shape)\n",
    "            x = self.part5(x)\n",
    "            x5 = self.conv5(x)\n",
    "      #      print(x5.shape)\n",
    "            x = w[0]*x1+w[1]*x2+w[2]*x3+w[3]*x4+w[4]*x5\n",
    "          #  x = nd.concat(x1, x2, x3, x4, x5, dim = 1)\n",
    "            x = self.dropout(x)\n",
    "            x = self.part6(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions used in training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  The following functions referred to the code provided in  https://d2l.ai/\n",
    "\n",
    "def try_all_gpus():  \n",
    "    ctxes = []\n",
    "    try:\n",
    "        for i in range(16):  \n",
    "            ctx = mx.gpu(i)\n",
    "            _ = nd.array([0], ctx=ctx)\n",
    "            ctxes.append(ctx)\n",
    "    except mx.base.MXNetError:\n",
    "        pass\n",
    "    if not ctxes:\n",
    "        ctxes = [mx.cpu()]\n",
    "    return ctxes\n",
    "\n",
    "ctx = try_all_gpus()\n",
    "\n",
    "def _get_batch(batch, ctx):\n",
    "    features, labels = batch\n",
    "    if labels.dtype != features.dtype:\n",
    "        labels = labels.astype(features.dtype)\n",
    "    return (gutils.split_and_load(features, ctx),\n",
    "            gutils.split_and_load(labels, ctx), features.shape[0])\n",
    "    \n",
    "def evaluate_accuracy(data_iter, net, ctx=[mx.cpu()]):\n",
    "    if isinstance(ctx, mx.Context):\n",
    "        ctx = [ctx]\n",
    "    acc_sum, n = nd.array([0]), 0\n",
    "    for batch in data_iter:\n",
    "        features, labels, _ = _get_batch(batch, ctx)\n",
    "        for X, y in zip(features, labels):\n",
    "            y = y.astype('float32')\n",
    "            acc_sum += (net(X).argmax(axis=1) == y).sum().copyto(mx.cpu())\n",
    "            n += y.size\n",
    "        acc_sum.wait_to_read()\n",
    "    return acc_sum.asscalar() / n\n",
    "\n",
    "def train(train_iter, test_iter, net, loss, trainer, ctx, num_epochs):\n",
    "    print('training on', ctx)\n",
    "    global hold_accuracy_train\n",
    "    global hold_accuracy_val\n",
    "    hold_accuracy_train = []    \n",
    "    hold_accuracy_val = []\n",
    "    if isinstance(ctx, mx.Context):\n",
    "        ctx = [ctx]\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, m, start = 0.0, 0.0, 0, 0, time.time()\n",
    "        for i, batch in enumerate(train_iter):\n",
    "            Xs, ys, batch_size = _get_batch(batch, ctx)\n",
    "            with autograd.record():\n",
    "                y_hats = [net(X) for X in Xs]\n",
    "                ls = [loss(y_hat, y) for y_hat, y in zip(y_hats, ys)]\n",
    "            for l in ls:\n",
    "                l.backward()\n",
    "            trainer.step(batch_size)\n",
    "            train_l_sum += sum([l.sum().asscalar() for l in ls])\n",
    "            n += sum([l.size for l in ls])\n",
    "            train_acc_sum += sum([(y_hat.argmax(axis=1) == y).sum().asscalar()\n",
    "                                 for y_hat, y in zip(y_hats, ys)])\n",
    "            m += sum([y.size for y in ys])\n",
    "        test_acc = evaluate_accuracy(test_iter, net, ctx)\n",
    "        hold_accuracy_val.append(test_acc)\n",
    "     #   train_acc = evaluate_accuracy(train_iter, net, ctx)\n",
    "        hold_accuracy_train.append(train_acc_sum / m)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, val acc %.3f, '\n",
    "              'time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / n, train_acc_sum / m, test_acc,\n",
    "                 time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataIterLoader():\n",
    "    def __init__(self, data_iter):\n",
    "        self.data_iter = data_iter\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.data_iter.reset()\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        batch = self.data_iter.__next__()\n",
    "        assert len(batch.data) == len(batch.label) == 1\n",
    "        data = batch.data[0]\n",
    "        label = batch.label[0]\n",
    "        return data, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(round, model, train_iter, val_iter, test_iter):\n",
    "    ctx = try_all_gpus()\n",
    "    loss = gloss.SoftmaxCrossEntropyLoss()\n",
    "    net1 = model     \n",
    "    net1.collect_params('.*modifiedmobilenet').initialize(init.Xavier(), ctx = ctx)\n",
    "    net1.collect_params().reset_ctx(ctx)\n",
    "    net1.hybridize()\n",
    "    epochs = 20\n",
    "    trainer1 = gluon.Trainer(net1.collect_params(), 'adam') #{'learning_rate': 0.1, 'wd': 1e-6}\n",
    "    train(train_iter, val_iter, net1, loss, trainer1, ctx, num_epochs=epochs)\n",
    "    final_test_acc = evaluate_accuracy(test_iter, net1, ctx)\n",
    "    print('modified_mobilenetv3_small:', final_test_acc)\n",
    "\n",
    "    epochs = 20\n",
    "    trainer2 = gluon.Trainer(net1.collect_params(), 'sgd') #{'learning_rate': 0.1, 'wd': 1e-6}\n",
    "    train(train_iter, val_iter, net1, loss, trainer2, ctx, num_epochs=epochs)\n",
    "    final_test_acc = evaluate_accuracy(test_iter, net1, ctx)\n",
    "    print('modified_mobilenetv3_small:', final_test_acc)\n",
    "    file_name = 'k_fold_cross_validation/models/net_'+str(round)+'.params'\n",
    "    net1.save_parameters(file_name)\n",
    "    return evaluate_accuracy(val_iter, net1, ctx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on [gpu(0), gpu(1), gpu(2), gpu(3)]\n",
      "epoch 1, loss 0.8015, train acc 0.731, val acc 0.950, time 44.3 sec\n",
      "epoch 2, loss 0.2999, train acc 0.910, val acc 0.970, time 39.6 sec\n",
      "epoch 3, loss 0.2004, train acc 0.946, val acc 0.963, time 38.6 sec\n",
      "epoch 4, loss 0.1378, train acc 0.962, val acc 0.980, time 39.3 sec\n",
      "epoch 5, loss 0.0998, train acc 0.976, val acc 0.982, time 39.0 sec\n",
      "epoch 6, loss 0.0970, train acc 0.976, val acc 0.984, time 39.2 sec\n",
      "epoch 7, loss 0.0749, train acc 0.979, val acc 0.981, time 39.0 sec\n",
      "epoch 8, loss 0.0635, train acc 0.983, val acc 0.979, time 38.9 sec\n",
      "epoch 9, loss 0.0501, train acc 0.985, val acc 0.972, time 39.2 sec\n",
      "epoch 10, loss 0.0571, train acc 0.986, val acc 0.981, time 39.3 sec\n",
      "epoch 11, loss 0.0486, train acc 0.986, val acc 0.934, time 39.6 sec\n",
      "epoch 12, loss 0.0449, train acc 0.989, val acc 0.979, time 38.6 sec\n",
      "epoch 13, loss 0.0406, train acc 0.990, val acc 0.958, time 39.0 sec\n",
      "epoch 14, loss 0.0389, train acc 0.991, val acc 0.984, time 38.9 sec\n",
      "epoch 15, loss 0.0224, train acc 0.995, val acc 0.990, time 39.1 sec\n",
      "epoch 16, loss 0.0206, train acc 0.995, val acc 0.987, time 38.8 sec\n",
      "epoch 17, loss 0.0282, train acc 0.993, val acc 0.974, time 40.1 sec\n",
      "epoch 18, loss 0.0189, train acc 0.995, val acc 0.984, time 38.8 sec\n",
      "epoch 19, loss 0.0159, train acc 0.997, val acc 0.980, time 39.1 sec\n",
      "epoch 20, loss 0.0268, train acc 0.993, val acc 0.985, time 39.0 sec\n",
      "modified_mobilenetv3_small: 0.986\n",
      "training on [gpu(0), gpu(1), gpu(2), gpu(3)]\n",
      "epoch 1, loss 0.0110, train acc 0.998, val acc 0.990, time 39.2 sec\n",
      "epoch 2, loss 0.0105, train acc 0.998, val acc 0.991, time 40.0 sec\n",
      "epoch 3, loss 0.0106, train acc 0.997, val acc 0.988, time 38.9 sec\n",
      "epoch 4, loss 0.0116, train acc 0.997, val acc 0.990, time 39.0 sec\n",
      "epoch 5, loss 0.0082, train acc 0.998, val acc 0.990, time 39.8 sec\n",
      "epoch 6, loss 0.0078, train acc 0.998, val acc 0.991, time 39.1 sec\n",
      "epoch 7, loss 0.0100, train acc 0.998, val acc 0.992, time 39.9 sec\n",
      "epoch 8, loss 0.0079, train acc 0.998, val acc 0.992, time 39.1 sec\n",
      "epoch 9, loss 0.0086, train acc 0.998, val acc 0.993, time 39.6 sec\n",
      "epoch 10, loss 0.0080, train acc 0.998, val acc 0.992, time 39.2 sec\n",
      "epoch 11, loss 0.0074, train acc 0.998, val acc 0.993, time 39.3 sec\n",
      "epoch 12, loss 0.0067, train acc 0.998, val acc 0.991, time 38.7 sec\n",
      "epoch 13, loss 0.0102, train acc 0.998, val acc 0.990, time 40.1 sec\n",
      "epoch 14, loss 0.0083, train acc 0.999, val acc 0.991, time 39.5 sec\n",
      "epoch 15, loss 0.0076, train acc 0.998, val acc 0.992, time 39.0 sec\n",
      "epoch 16, loss 0.0107, train acc 0.998, val acc 0.992, time 39.4 sec\n",
      "epoch 17, loss 0.0107, train acc 0.998, val acc 0.993, time 38.8 sec\n",
      "epoch 18, loss 0.0060, train acc 0.999, val acc 0.992, time 39.9 sec\n",
      "epoch 19, loss 0.0083, train acc 0.998, val acc 0.993, time 39.5 sec\n",
      "epoch 20, loss 0.0059, train acc 0.999, val acc 0.991, time 39.1 sec\n",
      "modified_mobilenetv3_small: 0.991\n",
      "training on [gpu(0), gpu(1), gpu(2), gpu(3)]\n",
      "epoch 1, loss 0.7953, train acc 0.729, val acc 0.969, time 111.4 sec\n",
      "epoch 2, loss 0.3029, train acc 0.914, val acc 0.935, time 39.4 sec\n",
      "epoch 3, loss 0.1847, train acc 0.951, val acc 0.970, time 38.8 sec\n",
      "epoch 4, loss 0.1167, train acc 0.972, val acc 0.967, time 39.2 sec\n",
      "epoch 5, loss 0.1139, train acc 0.969, val acc 0.981, time 39.4 sec\n",
      "epoch 6, loss 0.0875, train acc 0.974, val acc 0.981, time 39.3 sec\n",
      "epoch 7, loss 0.0612, train acc 0.983, val acc 0.986, time 38.8 sec\n",
      "epoch 8, loss 0.0753, train acc 0.982, val acc 0.920, time 38.7 sec\n",
      "epoch 9, loss 0.0471, train acc 0.988, val acc 0.984, time 38.9 sec\n",
      "epoch 10, loss 0.0374, train acc 0.992, val acc 0.986, time 39.5 sec\n",
      "epoch 11, loss 0.0428, train acc 0.990, val acc 0.972, time 39.1 sec\n",
      "epoch 12, loss 0.0477, train acc 0.987, val acc 0.979, time 38.9 sec\n",
      "epoch 13, loss 0.0345, train acc 0.992, val acc 0.983, time 38.5 sec\n",
      "epoch 14, loss 0.0386, train acc 0.991, val acc 0.983, time 39.2 sec\n",
      "epoch 15, loss 0.0220, train acc 0.995, val acc 0.988, time 39.2 sec\n",
      "epoch 16, loss 0.0187, train acc 0.995, val acc 0.984, time 38.7 sec\n",
      "epoch 17, loss 0.0301, train acc 0.993, val acc 0.984, time 38.9 sec\n",
      "epoch 18, loss 0.0238, train acc 0.995, val acc 0.980, time 38.7 sec\n",
      "epoch 19, loss 0.0178, train acc 0.994, val acc 0.985, time 39.5 sec\n",
      "epoch 20, loss 0.0223, train acc 0.996, val acc 0.980, time 39.5 sec\n",
      "modified_mobilenetv3_small: 0.981\n",
      "training on [gpu(0), gpu(1), gpu(2), gpu(3)]\n",
      "epoch 1, loss 0.0114, train acc 0.998, val acc 0.987, time 39.7 sec\n",
      "epoch 2, loss 0.0105, train acc 0.998, val acc 0.987, time 39.0 sec\n",
      "epoch 3, loss 0.0088, train acc 0.998, val acc 0.987, time 39.0 sec\n",
      "epoch 4, loss 0.0065, train acc 0.999, val acc 0.988, time 39.6 sec\n",
      "epoch 5, loss 0.0080, train acc 0.997, val acc 0.988, time 39.5 sec\n",
      "epoch 6, loss 0.0064, train acc 0.999, val acc 0.987, time 39.5 sec\n",
      "epoch 7, loss 0.0077, train acc 0.998, val acc 0.989, time 39.0 sec\n",
      "epoch 8, loss 0.0085, train acc 0.998, val acc 0.988, time 39.4 sec\n",
      "epoch 9, loss 0.0088, train acc 0.998, val acc 0.989, time 39.2 sec\n",
      "epoch 10, loss 0.0065, train acc 0.999, val acc 0.987, time 39.8 sec\n",
      "epoch 11, loss 0.0106, train acc 0.998, val acc 0.990, time 39.4 sec\n",
      "epoch 12, loss 0.0065, train acc 0.999, val acc 0.988, time 39.2 sec\n",
      "epoch 13, loss 0.0070, train acc 0.998, val acc 0.988, time 39.0 sec\n",
      "epoch 14, loss 0.0070, train acc 0.999, val acc 0.987, time 39.3 sec\n",
      "epoch 15, loss 0.0067, train acc 0.999, val acc 0.988, time 39.9 sec\n",
      "epoch 16, loss 0.0074, train acc 0.998, val acc 0.989, time 39.2 sec\n",
      "epoch 17, loss 0.0056, train acc 0.999, val acc 0.989, time 39.6 sec\n",
      "epoch 18, loss 0.0076, train acc 0.998, val acc 0.989, time 39.1 sec\n",
      "epoch 19, loss 0.0053, train acc 0.999, val acc 0.987, time 39.4 sec\n",
      "epoch 20, loss 0.0062, train acc 0.999, val acc 0.987, time 39.9 sec\n",
      "modified_mobilenetv3_small: 0.992\n",
      "training on [gpu(0), gpu(1), gpu(2), gpu(3)]\n",
      "epoch 1, loss 0.7787, train acc 0.745, val acc 0.969, time 116.9 sec\n",
      "epoch 2, loss 0.2976, train acc 0.915, val acc 0.975, time 38.9 sec\n",
      "epoch 3, loss 0.1815, train acc 0.950, val acc 0.978, time 38.9 sec\n",
      "epoch 4, loss 0.1232, train acc 0.970, val acc 0.912, time 39.2 sec\n",
      "epoch 5, loss 0.1076, train acc 0.973, val acc 0.945, time 43.7 sec\n",
      "epoch 6, loss 0.0737, train acc 0.982, val acc 0.964, time 39.1 sec\n",
      "epoch 7, loss 0.0729, train acc 0.981, val acc 0.987, time 38.6 sec\n",
      "epoch 8, loss 0.0576, train acc 0.985, val acc 0.980, time 38.5 sec\n",
      "epoch 9, loss 0.0440, train acc 0.989, val acc 0.985, time 39.0 sec\n",
      "epoch 10, loss 0.0334, train acc 0.991, val acc 0.984, time 39.5 sec\n",
      "epoch 11, loss 0.0535, train acc 0.986, val acc 0.961, time 39.1 sec\n",
      "epoch 12, loss 0.0312, train acc 0.993, val acc 0.986, time 38.9 sec\n",
      "epoch 13, loss 0.0414, train acc 0.989, val acc 0.980, time 38.5 sec\n",
      "epoch 14, loss 0.0286, train acc 0.994, val acc 0.976, time 39.0 sec\n",
      "epoch 15, loss 0.0285, train acc 0.991, val acc 0.930, time 39.2 sec\n",
      "epoch 16, loss 0.0196, train acc 0.995, val acc 0.981, time 39.1 sec\n",
      "epoch 17, loss 0.0191, train acc 0.994, val acc 0.988, time 39.2 sec\n",
      "epoch 18, loss 0.0175, train acc 0.995, val acc 0.977, time 38.7 sec\n",
      "epoch 19, loss 0.0231, train acc 0.994, val acc 0.982, time 39.2 sec\n",
      "epoch 20, loss 0.0211, train acc 0.995, val acc 0.980, time 39.6 sec\n",
      "modified_mobilenetv3_small: 0.985\n",
      "training on [gpu(0), gpu(1), gpu(2), gpu(3)]\n",
      "epoch 1, loss 0.0131, train acc 0.996, val acc 0.987, time 39.1 sec\n",
      "epoch 2, loss 0.0128, train acc 0.996, val acc 0.989, time 39.1 sec\n",
      "epoch 3, loss 0.0115, train acc 0.998, val acc 0.988, time 38.9 sec\n",
      "epoch 4, loss 0.0094, train acc 0.997, val acc 0.987, time 39.5 sec\n",
      "epoch 5, loss 0.0113, train acc 0.998, val acc 0.988, time 39.3 sec\n",
      "epoch 6, loss 0.0128, train acc 0.997, val acc 0.985, time 39.6 sec\n",
      "epoch 7, loss 0.0115, train acc 0.996, val acc 0.989, time 39.1 sec\n",
      "epoch 8, loss 0.0112, train acc 0.997, val acc 0.988, time 39.4 sec\n",
      "epoch 9, loss 0.0070, train acc 0.998, val acc 0.987, time 39.1 sec\n",
      "epoch 10, loss 0.0076, train acc 0.998, val acc 0.988, time 40.1 sec\n",
      "epoch 11, loss 0.0092, train acc 0.998, val acc 0.988, time 39.4 sec\n",
      "epoch 12, loss 0.0118, train acc 0.997, val acc 0.988, time 39.2 sec\n",
      "epoch 13, loss 0.0089, train acc 0.998, val acc 0.987, time 38.9 sec\n",
      "epoch 14, loss 0.0095, train acc 0.998, val acc 0.987, time 39.4 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, loss 0.0068, train acc 0.998, val acc 0.988, time 40.2 sec\n",
      "epoch 16, loss 0.0084, train acc 0.998, val acc 0.987, time 38.9 sec\n",
      "epoch 17, loss 0.0075, train acc 0.998, val acc 0.990, time 39.2 sec\n",
      "epoch 18, loss 0.0072, train acc 0.998, val acc 0.987, time 39.4 sec\n",
      "epoch 19, loss 0.0045, train acc 0.999, val acc 0.990, time 39.1 sec\n",
      "epoch 20, loss 0.0086, train acc 0.998, val acc 0.988, time 40.3 sec\n",
      "modified_mobilenetv3_small: 0.992\n",
      "training on [gpu(0), gpu(1), gpu(2), gpu(3)]\n",
      "epoch 1, loss 0.8097, train acc 0.731, val acc 0.949, time 97.3 sec\n",
      "epoch 2, loss 0.3298, train acc 0.909, val acc 0.958, time 39.3 sec\n",
      "epoch 3, loss 0.2008, train acc 0.946, val acc 0.970, time 38.5 sec\n",
      "epoch 4, loss 0.1242, train acc 0.967, val acc 0.972, time 38.9 sec\n",
      "epoch 5, loss 0.1015, train acc 0.969, val acc 0.959, time 39.8 sec\n",
      "epoch 6, loss 0.0766, train acc 0.979, val acc 0.981, time 39.2 sec\n",
      "epoch 7, loss 0.0762, train acc 0.980, val acc 0.974, time 38.9 sec\n",
      "epoch 8, loss 0.0720, train acc 0.981, val acc 0.977, time 38.6 sec\n",
      "epoch 9, loss 0.0668, train acc 0.982, val acc 0.984, time 38.9 sec\n",
      "epoch 10, loss 0.0351, train acc 0.991, val acc 0.990, time 39.4 sec\n",
      "epoch 11, loss 0.0217, train acc 0.995, val acc 0.987, time 39.0 sec\n",
      "epoch 12, loss 0.0458, train acc 0.988, val acc 0.978, time 38.9 sec\n",
      "epoch 13, loss 0.0462, train acc 0.988, val acc 0.980, time 38.6 sec\n",
      "epoch 14, loss 0.0352, train acc 0.991, val acc 0.943, time 38.8 sec\n",
      "epoch 15, loss 0.0257, train acc 0.993, val acc 0.987, time 39.5 sec\n",
      "epoch 16, loss 0.0194, train acc 0.996, val acc 0.975, time 39.1 sec\n",
      "epoch 17, loss 0.0303, train acc 0.992, val acc 0.977, time 38.9 sec\n",
      "epoch 18, loss 0.0182, train acc 0.994, val acc 0.970, time 38.6 sec\n",
      "epoch 19, loss 0.0239, train acc 0.994, val acc 0.987, time 39.0 sec\n",
      "epoch 20, loss 0.0294, train acc 0.993, val acc 0.990, time 39.4 sec\n",
      "modified_mobilenetv3_small: 0.986\n",
      "training on [gpu(0), gpu(1), gpu(2), gpu(3)]\n",
      "epoch 1, loss 0.0109, train acc 0.997, val acc 0.990, time 39.3 sec\n",
      "epoch 2, loss 0.0110, train acc 0.997, val acc 0.991, time 39.0 sec\n",
      "epoch 3, loss 0.0093, train acc 0.998, val acc 0.991, time 38.9 sec\n",
      "epoch 4, loss 0.0096, train acc 0.998, val acc 0.992, time 39.6 sec\n",
      "epoch 5, loss 0.0101, train acc 0.998, val acc 0.990, time 39.6 sec\n",
      "epoch 6, loss 0.0077, train acc 0.998, val acc 0.992, time 39.3 sec\n",
      "epoch 7, loss 0.0066, train acc 0.999, val acc 0.990, time 39.3 sec\n",
      "epoch 8, loss 0.0102, train acc 0.997, val acc 0.991, time 39.1 sec\n",
      "epoch 9, loss 0.0063, train acc 0.999, val acc 0.990, time 39.2 sec\n",
      "epoch 10, loss 0.0079, train acc 0.998, val acc 0.991, time 39.8 sec\n",
      "epoch 11, loss 0.0092, train acc 0.998, val acc 0.990, time 39.1 sec\n",
      "epoch 12, loss 0.0070, train acc 0.999, val acc 0.991, time 39.4 sec\n",
      "epoch 13, loss 0.0073, train acc 0.998, val acc 0.990, time 38.8 sec\n",
      "epoch 14, loss 0.0092, train acc 0.998, val acc 0.991, time 39.1 sec\n",
      "epoch 15, loss 0.0075, train acc 0.998, val acc 0.990, time 39.9 sec\n",
      "epoch 16, loss 0.0064, train acc 0.999, val acc 0.991, time 38.8 sec\n",
      "epoch 17, loss 0.0046, train acc 0.999, val acc 0.989, time 38.9 sec\n",
      "epoch 18, loss 0.0095, train acc 0.998, val acc 0.992, time 39.0 sec\n",
      "epoch 19, loss 0.0069, train acc 0.999, val acc 0.991, time 39.3 sec\n",
      "epoch 20, loss 0.0052, train acc 0.999, val acc 0.991, time 40.2 sec\n",
      "modified_mobilenetv3_small: 0.996\n",
      "training on [gpu(0), gpu(1), gpu(2), gpu(3)]\n",
      "epoch 1, loss 0.9156, train acc 0.690, val acc 0.955, time 131.8 sec\n",
      "epoch 2, loss 0.3455, train acc 0.897, val acc 0.965, time 39.6 sec\n",
      "epoch 3, loss 0.2097, train acc 0.944, val acc 0.984, time 38.9 sec\n",
      "epoch 4, loss 0.1482, train acc 0.960, val acc 0.980, time 39.1 sec\n",
      "epoch 5, loss 0.1109, train acc 0.972, val acc 0.959, time 39.8 sec\n",
      "epoch 6, loss 0.1212, train acc 0.967, val acc 0.966, time 38.9 sec\n",
      "epoch 7, loss 0.0834, train acc 0.975, val acc 0.951, time 39.2 sec\n",
      "epoch 8, loss 0.0646, train acc 0.983, val acc 0.966, time 39.0 sec\n",
      "epoch 9, loss 0.0755, train acc 0.982, val acc 0.989, time 38.9 sec\n",
      "epoch 10, loss 0.0389, train acc 0.991, val acc 0.988, time 39.7 sec\n",
      "epoch 11, loss 0.0404, train acc 0.990, val acc 0.982, time 39.3 sec\n",
      "epoch 12, loss 0.0459, train acc 0.990, val acc 0.987, time 39.4 sec\n",
      "epoch 13, loss 0.0477, train acc 0.986, val acc 0.982, time 38.6 sec\n",
      "epoch 14, loss 0.0224, train acc 0.995, val acc 0.989, time 39.0 sec\n",
      "epoch 15, loss 0.0345, train acc 0.992, val acc 0.971, time 39.4 sec\n",
      "epoch 16, loss 0.0255, train acc 0.994, val acc 0.968, time 38.9 sec\n",
      "epoch 17, loss 0.0343, train acc 0.991, val acc 0.987, time 39.1 sec\n",
      "epoch 18, loss 0.0402, train acc 0.990, val acc 0.979, time 39.0 sec\n",
      "epoch 19, loss 0.0232, train acc 0.994, val acc 0.987, time 39.2 sec\n",
      "epoch 20, loss 0.0202, train acc 0.995, val acc 0.987, time 39.8 sec\n",
      "modified_mobilenetv3_small: 0.983\n",
      "training on [gpu(0), gpu(1), gpu(2), gpu(3)]\n",
      "epoch 1, loss 0.0138, train acc 0.997, val acc 0.990, time 39.3 sec\n",
      "epoch 2, loss 0.0169, train acc 0.997, val acc 0.991, time 39.6 sec\n",
      "epoch 3, loss 0.0103, train acc 0.998, val acc 0.991, time 39.2 sec\n",
      "epoch 4, loss 0.0083, train acc 0.998, val acc 0.990, time 39.7 sec\n",
      "epoch 5, loss 0.0141, train acc 0.997, val acc 0.991, time 39.6 sec\n",
      "epoch 6, loss 0.0089, train acc 0.999, val acc 0.989, time 39.5 sec\n",
      "epoch 7, loss 0.0082, train acc 0.998, val acc 0.990, time 39.2 sec\n",
      "epoch 8, loss 0.0100, train acc 0.999, val acc 0.991, time 39.2 sec\n",
      "epoch 9, loss 0.0101, train acc 0.998, val acc 0.993, time 39.2 sec\n",
      "epoch 10, loss 0.0081, train acc 0.998, val acc 0.991, time 40.0 sec\n",
      "epoch 11, loss 0.0103, train acc 0.998, val acc 0.993, time 39.5 sec\n",
      "epoch 12, loss 0.0117, train acc 0.998, val acc 0.993, time 39.6 sec\n",
      "epoch 13, loss 0.0080, train acc 0.998, val acc 0.992, time 39.1 sec\n",
      "epoch 14, loss 0.0087, train acc 0.999, val acc 0.993, time 39.6 sec\n",
      "epoch 15, loss 0.0071, train acc 0.999, val acc 0.988, time 40.1 sec\n",
      "epoch 16, loss 0.0090, train acc 0.998, val acc 0.990, time 38.9 sec\n",
      "epoch 17, loss 0.0050, train acc 0.999, val acc 0.988, time 39.2 sec\n",
      "epoch 18, loss 0.0085, train acc 0.998, val acc 0.992, time 39.4 sec\n",
      "epoch 19, loss 0.0100, train acc 0.998, val acc 0.994, time 39.5 sec\n",
      "epoch 20, loss 0.0077, train acc 0.998, val acc 0.991, time 40.1 sec\n",
      "modified_mobilenetv3_small: 0.992\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for i in range(5):\n",
    "    rec_path = os.path.expanduser('k_fold_cross_validation/rec/')\n",
    "\n",
    "    # You need to specify ``root`` for ImageNet if you extracted the images into\n",
    "    # a different folder\n",
    "    train_data = ImageRecordIter(\n",
    "        path_imgrec = os.path.join(rec_path, 'Train_rec_'+str(i)+'.rec'),\n",
    "        path_imgidx = os.path.join(rec_path, 'Train_rec_'+str(i)+'.idx'),\n",
    "        resize = 299,\n",
    "        data_shape  = (3, 299, 299),\n",
    "        batch_size  = 128,   \n",
    "        preprocess_threads = 8,\n",
    "        shuffle = True,\n",
    "    )\n",
    "\n",
    "    val_data = ImageRecordIter(\n",
    "        path_imgrec = os.path.join(rec_path, 'Val_rec_'+str(i)+'.rec'),\n",
    "        path_imgidx = os.path.join(rec_path, 'Val_rec_'+str(i)+'.idx'),\n",
    "        resize = 299,\n",
    "        data_shape  = (3, 299, 299),\n",
    "        batch_size  = 64, \n",
    "        preprocess_threads = 8,\n",
    "        shuffle = False\n",
    "    )\n",
    "\n",
    "    test_data = ImageRecordIter(\n",
    "        path_imgrec = os.path.join(rec_path, 'Test_rec.rec'),\n",
    "        path_imgidx = os.path.join(rec_path, 'Test_rec.idx'),\n",
    "        resize = 299,\n",
    "        data_shape  = (3, 299, 299),\n",
    "        batch_size  = 100, \n",
    "        preprocess_threads = 8,\n",
    "        shuffle = False,\n",
    "    )\n",
    "\n",
    "    train_iter = DataIterLoader(train_data)\n",
    "    val_iter = DataIterLoader(val_data)\n",
    "    test_iter = DataIterLoader(test_data)\n",
    "\n",
    "    acc = get_score(i, modifiedMobileNet(), train_iter, val_iter, test_iter)\n",
    "    result.append(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(round, train_iter, val_iter, test_iter):\n",
    "    model_name = 'mobilenetv3_small'\n",
    "    classes = 5\n",
    "    finetune_net = get_model(model_name, pretrained=True)\n",
    "    output = nn.HybridSequential()\n",
    "    output.add(nn.Conv2D(classes, (1,1)))\n",
    "    output.add(nn.Flatten())\n",
    "    with finetune_net.name_scope():\n",
    "        finetune_net.output = output\n",
    "    ctx = try_all_gpus()\n",
    "    loss = gloss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "\n",
    "    finetune_net.output.initialize(init.Xavier(), ctx = ctx)\n",
    "    finetune_net.collect_params().reset_ctx(ctx)\n",
    "    finetune_net.hybridize()\n",
    "    epochs = 20\n",
    "    trainer1 = gluon.Trainer(finetune_net.collect_params(), 'adam') #{'learning_rate': 0.1, 'wd': 1e-6}\n",
    "    train(train_iter, val_iter, finetune_net, loss, trainer1, ctx, num_epochs=epochs)\n",
    "    final_test_acc = evaluate_accuracy(test_iter, finetune_net, ctx)\n",
    "    print('original_mobilenetv3_small:', final_test_acc)\n",
    "\n",
    "    epochs = 20\n",
    "    trainer2 = gluon.Trainer(finetune_net.collect_params(), 'sgd') #{'learning_rate': 0.1, 'wd': 1e-6}\n",
    "    train(train_iter, val_iter, finetune_net, loss, trainer2, ctx, num_epochs=epochs)\n",
    "    final_test_acc = evaluate_accuracy(test_iter, finetune_net, ctx)\n",
    "    print('original_mobilenetv3_small:', final_test_acc)\n",
    "    file_name = 'k_fold_cross_validation_3/models/original_'+str(round)+'.params'\n",
    "    finetune_net.save_parameters(file_name)\n",
    "    return evaluate_accuracy(test_iter, finetune_net, ctx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "#os.mkdir('k_fold_cross_validation_4/models')\n",
    "for i in range(5):\n",
    "    rec_path = os.path.expanduser('k_fold_cross_validation/rec/')\n",
    "\n",
    "    # You need to specify ``root`` for ImageNet if you extracted the images into\n",
    "    # a different folder\n",
    "    train_data = ImageRecordIter(\n",
    "        path_imgrec = os.path.join(rec_path, 'Train_rec_'+str(i)+'.rec'),\n",
    "        path_imgidx = os.path.join(rec_path, 'Train_rec_'+str(i)+'.idx'),\n",
    "        resize = 299,\n",
    "        data_shape  = (3, 299, 299),\n",
    "        batch_size  = 128,   \n",
    "        preprocess_threads = 8,\n",
    "        shuffle = True,\n",
    "    )\n",
    "\n",
    "    val_data = ImageRecordIter(\n",
    "        path_imgrec = os.path.join(rec_path, 'Val_rec_'+str(i)+'.rec'),\n",
    "        path_imgidx = os.path.join(rec_path, 'Val_rec_'+str(i)+'.idx'),\n",
    "        resize = 299,\n",
    "        data_shape  = (3, 299, 299),\n",
    "        batch_size  = 64, \n",
    "        preprocess_threads = 8,\n",
    "        shuffle = False\n",
    "    )\n",
    "\n",
    "    test_data = ImageRecordIter(\n",
    "        path_imgrec = os.path.join(rec_path, 'Test_rec.rec'),\n",
    "        path_imgidx = os.path.join(rec_path, 'Test_rec.idx'),\n",
    "        resize = 299,\n",
    "        data_shape  = (3, 299, 299),\n",
    "        batch_size  = 100, \n",
    "        preprocess_threads = 8,\n",
    "        shuffle = False,\n",
    "    )\n",
    "\n",
    "    train_iter = DataIterLoader(train_data)\n",
    "    val_iter = DataIterLoader(val_data)\n",
    "    test_iter = DataIterLoader(test_data)\n",
    "\n",
    "    acc = get_score(i, train_iter, val_iter, test_iter)\n",
    "    result.append(acc)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
