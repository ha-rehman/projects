{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "672bdc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "7e893edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_name):\n",
    "    print(\"Start Reading File, {}\".format(file_name.rsplit('/', 1)[-1]))\n",
    "    \n",
    "    # open file\n",
    "    with open(training_file) as f:\n",
    "        words, tags = [], []\n",
    "        # iterate the file line by line\n",
    "        for line in tqdm(f.readlines()):\n",
    "            # split the line by last / to seperate the word and tag\n",
    "            word, tag = line.strip().rsplit('/', 1)\n",
    "            words.append(word) # append in words list\n",
    "            tags.append(tag) # append in tags list\n",
    "            \n",
    "    print(\"Prepare Dataset for File {}...\".format(file_name.rsplit('/', 1)[-1]))\n",
    "    df = pd.DataFrame([words, tags], index=['Words', 'Tags']).T # prepare dataset\n",
    "    print(\"Successfuly Read and Prepare File, {} \\U0001f600 \\n\\n\".format(file_name.rsplit('/', 1)[-1])) \n",
    "    return df\n",
    "\n",
    "def train_tagger(dataframe):\n",
    "    print(\"Start Training of POS Tagger....\")\n",
    "    \n",
    "    tagger_words = []\n",
    "    tagger_tags = []\n",
    "    distinct_words = dataframe['Words'].unique()\n",
    "    for word in tqdm(distinct_words):\n",
    "        temp_df = dataframe[dataframe['Words'] == word]\n",
    "        max_prob_tag = temp_df['Tags'].value_counts().index[0]\n",
    "        tagger_words.append(word)\n",
    "        tagger_tags.append(max_prob_tag)\n",
    "        \n",
    "    print(\"Saving the Probabilities of Tagger..\")\n",
    "    tagger_df = pd.DataFrame([tagger_words, tagger_tags], index=['Words', 'Tags']).T\n",
    "    tagger_df.to_csv(\"tagger_df.csv\", index=False)\n",
    "    print(\"Successfuly Train the POS Tagger! \\U0001f600 \\n\\n\")\n",
    "    return tagger_df\n",
    "\n",
    "def prediction_0(testing_file, tagger_df):\n",
    "    print(\"Start POS Tagging of Test Words....\")\n",
    "    # open file\n",
    "    with open(testing_file) as f:\n",
    "        words, tags = [], []\n",
    "        # remove previouslt existing file\n",
    "        os.remove('data/pos-test-answers-0.txt') if os.path.exists('data/pos-test-answers-0.txt') else None\n",
    "        pred_files = open(\"data/pos-test-answers-0.txt\",\"w+\") # create new file\n",
    "        \n",
    "        # iterate the file line by line\n",
    "        for line in tqdm(f.readlines()):\n",
    "            word = line.strip() # remove extra white spaces from both side of the word\n",
    "            # assign tag according to given critaira\n",
    "            tag = tagger_df[tagger_df['Words'] == word]['Tags'].values[0] if (word in tagger_df['Words'].values) else 'NN'\n",
    "                \n",
    "            words.append(word) # append words\n",
    "            tags.append(tag) # append tags\n",
    "            pred_files.write(word+\"/\"+tag+\"\\n\") # write words and their tags\n",
    "    print(\"Successfuly Tagged POS Tags to Test Words! \\U0001f600 \\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7018e0f2",
   "metadata": {},
   "source": [
    "# POS Tagger (Mode 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c1a4833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Reading File, pos-train.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1232377/1232377 [00:00<00:00, 1535617.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare Dataset for File pos-train.txt...\n",
      "Successfuly Read and Prepare File, pos-train.txt ðŸ˜€ \n",
      "\n",
      "\n",
      "Start Training of POS Tagger....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50496/50496 [59:17<00:00, 14.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the Probabilities of Tagger..\n",
      "Successfuly Train the POS Tagger! ðŸ˜€ \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_file = \"data/pos-train.txt\"\n",
    "testing_file = 'data/pos-test.txt'\n",
    "train_df = read_file(training_file)\n",
    "tagger_df = train_tagger(train_df)\n",
    "prediction_0(testing_file, tagger_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "79babf14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start POS Tagging of Test Words....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56824/56824 [08:32<00:00, 110.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfuly Tagged POS Tags to Test Words! ðŸ˜€ \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prediction(testing_file, tagger_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0fc2e4",
   "metadata": {},
   "source": [
    "# POS Tagger (Mode 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "3f4eb4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NN filling rules\n",
    "def is_special_character_only(word):\n",
    "    regex = re.compile(\"[A-Za-z0-9]\")\n",
    "    if(regex.search(word) != None):\n",
    "        return \"NN\" \n",
    "    regex = re.compile(\"[^A-Za-z0-9]\")\n",
    "    return re.findall(regex, word)[0] if(regex.search(word) != None) else \"NN\"\n",
    "\n",
    "def is_digit_only(word):\n",
    "    return \"CD\" if(re.match('^\\d+(\\.\\d+)*$', word) != None) else \"NN\"\n",
    "\n",
    "def is_hyphenated_digits(word):\n",
    "    regex = re.compile(r'\\d+(?:-\\d+)+')\n",
    "    return \"NNP\" if(regex.search(word) != None) else \"NN\"\n",
    "\n",
    "def is_hyphenated_words(word):\n",
    "    regex = re.compile(r'[a-zA-Z]+(?:-[a-zA-Z]+)+')\n",
    "    return \"JJ\" if(regex.search(word) != None) else \"NN\"\n",
    "\n",
    "def is_contain_year(word):\n",
    "    string = 'year'\n",
    "    return \"JJ\" if string in word and (len(string) < len(word)) else \"NN\"\n",
    "\n",
    "\n",
    "# error removing rules\n",
    "def is_selling(word, tag):\n",
    "    return \"NN\" if word == \"selling\" and tag == \"VBG\" else tag\n",
    "\n",
    "def is_calls(word, tag):\n",
    "    return \"NNS\" if word == \"calls\" and tag == \"VBZ\" else tag\n",
    "\n",
    "def is_fall(word, tag):\n",
    "    return \"VB\" if word == \"fall\" and tag == \"NN\" else tag\n",
    "\n",
    "def validate_last_character(word, tag):\n",
    "    if word[-1] == \"s\" and tag == \"NNPS\":\n",
    "        countries = ['Americans', 'Soviets', 'Olympics', 'Workers', 'Yankees', 'Greeks',\n",
    "       'Germans', 'Moslems', 'Europeans', 'Jews', 'Republicans',\n",
    "       'Democrats', 'Representatives', 'Treasurys']\n",
    "        return tag if word in countries else \"NNP\"\n",
    "    return tag\n",
    "\n",
    "\n",
    "# prediction module using updated rules\n",
    "def prediction_1(testing_file, tagger_df):\n",
    "    print(\"Start POS Tagging of Test Words....\")\n",
    "    # open file\n",
    "    with open(testing_file) as f:\n",
    "        words, tags = [], []\n",
    "        # remove previouslt existing file\n",
    "        os.remove('data/pos-test-answers-1.txt') if os.path.exists('data/pos-test-answers-1.txt') else None\n",
    "        pred_files = open(\"data/pos-test-answers-1.txt\",\"w+\") # create new file\n",
    "        \n",
    "        # iterate the file line by line\n",
    "        for line in tqdm(f.readlines()):\n",
    "            word = line.strip() # remove extra white spaces from both side of the word\n",
    "            # assign tag according updated critaria of NN\n",
    "            if word in tagger_df['Words'].values:\n",
    "                tag = tagger_df[tagger_df['Words'] == word]['Tags'].values[0]\n",
    "            else:\n",
    "                tag = is_special_character_only(word)\n",
    "                tag = is_digit_only(word) if tag == \"NN\" else tag\n",
    "                tag = is_hyphenated_words(word) if tag == \"NN\" else tag\n",
    "                tag = is_hyphenated_digits(word) if tag == \"NN\" else tag\n",
    "                tag = is_contain_year(word) if tag == \"NN\" else tag\n",
    "                \n",
    "            # remove error by manual rules\n",
    "            tag = is_selling(word, tag)\n",
    "            tag = is_calls(word, tag)\n",
    "            tag = is_fall(word, tag)\n",
    "            tag = validate_last_character(word, tag)\n",
    "                \n",
    "            words.append(word) # append words\n",
    "            tags.append(tag) # append tags\n",
    "            pred_files.write(word+\"/\"+tag+\"\\n\") # write words and their tags\n",
    "    print(\"Successfuly Tagged POS Tags to Test Words! \\U0001f600 \\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "00e76b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start POS Tagging of Test Words....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56824/56824 [05:07<00:00, 184.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfuly Tagged POS Tags to Test Words! ðŸ˜€ \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training_file = \"data/pos-train.txt\"\n",
    "testing_file = 'data/pos-test.txt'\n",
    "# train_df = read_file(training_file)\n",
    "# tagger_df = train_tagger(train_df)\n",
    "tagger_df = pd.read_csv(\"tagger_df.csv\")\n",
    "prediction_1(testing_file, tagger_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d31c12f",
   "metadata": {},
   "source": [
    "# POS Tagger Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "9361f563",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tags(file_name):\n",
    "    # open file\n",
    "    with open(file_name) as f:\n",
    "        tags = []\n",
    "        words = []\n",
    "        # ite rate the file line by line\n",
    "        for line in f.readlines():\n",
    "            # split the line by last / to seperate the word and tag\n",
    "            word, tag = line.strip().rsplit('/', 1)\n",
    "            tags.append(tag) # append in tags list\n",
    "            words.append(word)\n",
    "            \n",
    "    df = pd.DataFrame([words, tags], index=['Words', 'Tags']).T # prepare dataset\n",
    "    ff = str(file_name.rsplit('/', 1)[-1].rsplit('.', 1)[0])+\".csv\"\n",
    "    df.to_csv(ff, index=False)\n",
    "    \n",
    "    return tags\n",
    "\n",
    "def evaluate_tags(output_file, test_tags, pred_tags):\n",
    "    # compute accuracy score segment\n",
    "    accuracy=[]\n",
    "    for i in range(len(test_tags)):\n",
    "        accuracy.append(1) if test_tags[i]==pred_tags[i] else accuracy.append(0)\n",
    "            \n",
    "    acc_score = np.mean(accuracy)\n",
    "    print(\"Accuracy Score: {}\".format(acc_score))\n",
    "    \n",
    "    # calculate confusion metrix block\n",
    "    tags_name = sorted(set(test_tags) | set (pred_tags))\n",
    "    c = len(tags_name) # Number of classes \n",
    "    confusion_metrix_ = np.zeros((c, c))\n",
    "\n",
    "    for i in range(len(test_tags)):\n",
    "        confusion_metrix_[tags_name.index(pred_tags[i])][tags_name.index(test_tags[i])] += 1\n",
    "\n",
    "    # write confusion metrix in a file\n",
    "    os.remove(output_file) if os.path.exists(output_file) else None # remove previouslt existing file\n",
    "    eval_file = open(output_file,\"w+\") # create new file\n",
    "    \n",
    "    for i in tqdm(range(0, len(tags_name))):\n",
    "        preds = confusion_metrix_[i]\n",
    "        true_false_positives = np.where(preds != 0)[0]\n",
    "        for index in true_false_positives:\n",
    "            eval_file.write(tags_name[i]+\" \"+tags_name[index]+\" : \"+str(int(preds[index]))+\" \\n\")\n",
    "    \n",
    "    print(\"Confusion Metrix Results are Write Successfuly in {} \\U0001f600 \\n\\n\".format(output_file.rsplit('/', 1)[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "622e65c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.926386737998029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:00<00:00, 44399.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Metrix Results are Write Successfuly in pos-test-1-eval.txt ðŸ˜€ \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_tag_file = \"data/pos-key.txt\"\n",
    "pred_tag_file = \"data/pos-test-answers-1.txt\"\n",
    "output_file = 'data/pos-test-1-eval.txt'\n",
    "test_tags = read_tags(test_tag_file)\n",
    "pred_tags = read_tags(pred_tag_file)\n",
    "evaluate_tags(output_file, test_tags, pred_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87adf93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
