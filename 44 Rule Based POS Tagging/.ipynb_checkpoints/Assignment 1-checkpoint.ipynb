{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "672bdc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1720eb0",
   "metadata": {},
   "source": [
    "# POS Tagger (Mode 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e70120bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_name):\n",
    "    print(\"Start Reading File, {}\".format(file_name.rsplit('/', 1)[-1]))\n",
    "    \n",
    "    # open file\n",
    "    with open(training_file) as f:\n",
    "        words, tags = [], []\n",
    "        # iterate the file line by line\n",
    "        for line in tqdm(f.readlines()):\n",
    "            # split the line by last / to seperate the word and tag\n",
    "            word, tag = line.strip().rsplit('/', 1)\n",
    "            words.append(word) # append in words list\n",
    "            tags.append(tag) # append in tags list\n",
    "            \n",
    "    print(\"Prepare Dataset for File {}...\".format(file_name.rsplit('/', 1)[-1]))\n",
    "    df = pd.DataFrame([words, tags], index=['Words', 'Tags']).T # prepare dataset\n",
    "    print(\"Successfuly Read and Prepare File, {} \\U0001f600 \\n\\n\".format(file_name.rsplit('/', 1)[-1])) \n",
    "    return df\n",
    "\n",
    "def train_tagger(dataframe):\n",
    "    print(\"Start Training of POS Tagger....\")\n",
    "    \n",
    "    tagger_words = []\n",
    "    tagger_tags = []\n",
    "    distinct_words = dataframe['Words'].unique()\n",
    "    for word in tqdm(distinct_words):\n",
    "        temp_df = dataframe[dataframe['Words'] == word]\n",
    "        max_prob_tag = temp_df['Tags'].value_counts().index[0]\n",
    "        tagger_words.append(word)\n",
    "        tagger_tags.append(max_prob_tag)\n",
    "        \n",
    "    print(\"Saving the Probabilities of Tagger..\")\n",
    "    tagger_df = pd.DataFrame([tagger_words, tagger_tags], index=['Words', 'Tags']).T\n",
    "    tagger_df.to_csv(\"tagger_df.csv\", index=False)\n",
    "    print(\"Successfuly Train the POS Tagger! \\U0001f600 \\n\\n\")\n",
    "    return tagger_df\n",
    "\n",
    "def prediction(testing_file, tagger_df):\n",
    "    print(\"Start POS Tagging of Test Words....\")\n",
    "    # open file\n",
    "    with open(testing_file) as f:\n",
    "        words, tags = [], []\n",
    "        # remove previouslt existing file\n",
    "        os.remove('data/pos-test-answers-0.txt') if os.path.exists('data/pos-test-answers-0.txt') else None\n",
    "        pred_files = open(\"data/pos-test-answers-0.txt\",\"w+\") # create new file\n",
    "        \n",
    "        # iterate the file line by line\n",
    "        for line in tqdm(f.readlines()):\n",
    "            word = line.strip() # remove extra white spaces from both side of the word\n",
    "            # assign tag according to given critaira\n",
    "            tag = tagger_df[tagger_df['Words'] == word]['Tags'].values[0] if (word in tagger_df['Words'].values) else 'NN'\n",
    "                \n",
    "            words.append(word) # append words\n",
    "            tags.append(tag) # append tags\n",
    "            pred_files.write(word+\"/\"+tag+\"\\n\") # write words and their tags\n",
    "    print(\"Successfuly Tagged POS Tags to Test Words! \\U0001f600 \\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87cc57bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Reading File, pos-train.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1232377/1232377 [00:00<00:00, 1535617.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare Dataset for File pos-train.txt...\n",
      "Successfuly Read and Prepare File, pos-train.txt ðŸ˜€ \n",
      "\n",
      "\n",
      "Start Training of POS Tagger....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50496/50496 [59:17<00:00, 14.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the Probabilities of Tagger..\n",
      "Successfuly Train the POS Tagger! ðŸ˜€ \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_file = \"data/pos-train.txt\"\n",
    "testing_file = 'data/pos-test.txt'\n",
    "train_df = read_file(training_file)\n",
    "tagger_df = train_tagger(train_df)\n",
    "prediction(testing_file, tagger_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f28d3ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start POS Tagging of Test Words....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56824/56824 [08:32<00:00, 110.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfuly Tagged POS Tags to Test Words! ðŸ˜€ \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prediction(testing_file, tagger_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60224c41",
   "metadata": {},
   "source": [
    "# POS Tagger (Mode 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "2d33546e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv(\"pos-test-answers-0.csv\")\n",
    "df_2 = pd.read_csv(\"pos-key.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "0170527e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1['Tags_original'] = df_2['Tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "777ae3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_1[df_1[\"Tags\"] == \"NN\"]\n",
    "df_1 = df_1[df_1[\"Tags_original\"] != df_1[\"Tags\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "e161c026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = df_1[df_1[\"Words\"] == \"fall\"]\n",
    "# df_2 = df_1[df_1[\"Tags_original\"] != df_1[\"Tags\"]]\n",
    "df_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "44ab3703",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.to_csv(\"tags_VBG.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "8aeb015a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    " \n",
    "# Function checks if the string\n",
    "# contains any special character\n",
    "def is_special_character_only(word):\n",
    "    regex = re.compile(\"[^A-Za-z0-9]\")\n",
    "    return True if(regex.search(word) != None) else False\n",
    "\n",
    "\n",
    "def is_digit_only(word):\n",
    "    return bool(re.match('^\\d+(\\.\\d+)*$', word))\n",
    "\n",
    "def is_hyphenated_digits(word):\n",
    "    regex = re.compile(r'\\d+(?:-\\d+)+')\n",
    "    return True if(regex.search(word) != None) else False\n",
    "\n",
    "def is_hyphenated_words(word):\n",
    "    regex = re.compile(r'[a-zA-Z]+(?:-[a-zA-Z]+)+')\n",
    "    return True if(regex.search(word) != None) else False\n",
    "\n",
    "def is_contain_year(word):\n",
    "    string = 'year'\n",
    "    return True if string in word and (len(string) < len(word)) else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "55105ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = \"%\"\n",
    "if is_special_character_only(word):\n",
    "    print(\"ok\")\n",
    "else:\n",
    "    print(\"okk\")\n",
    "\n",
    "word = '123'\n",
    "is_digit_only(word)\n",
    "\n",
    "word = '324-423329'\n",
    "is_hyphenated_word(word)\n",
    "\n",
    "word = '454-45423'\n",
    "is_hyphenated_digits(word)\n",
    "\n",
    "word = '454-45423'\n",
    "is_hyphenated_digits(word)\n",
    "\n",
    "word = \"year\"\n",
    "is_contain_year(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113e923a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_selling(word, tag):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d5edbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ee32856",
   "metadata": {},
   "source": [
    "# POS Tagger Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c0f99e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tags(file_name):\n",
    "    # open file\n",
    "    with open(file_name) as f:\n",
    "        tags = []\n",
    "        words = []\n",
    "        # ite rate the file line by line\n",
    "        for line in f.readlines():\n",
    "            # split the line by last / to seperate the word and tag\n",
    "            word, tag = line.strip().rsplit('/', 1)\n",
    "            tags.append(tag) # append in tags list\n",
    "#             words.append(word)\n",
    "            \n",
    "#     df = pd.DataFrame([words, tags], index=['Words', 'Tags']).T # prepare dataset\n",
    "#     ff = str(file_name.rsplit('/', 1)[-1].rsplit('.', 1)[0])+\".csv\"\n",
    "#     df.to_csv(ff, index=False)\n",
    "    \n",
    "    return tags\n",
    "\n",
    "def evaluate_tags(output_file, test_tags, pred_tags):\n",
    "    # compute accuracy score segment\n",
    "    accuracy=[]\n",
    "    for i in range(len(test_tags)):\n",
    "        accuracy.append(1) if test_tags[i]==pred_tags[i] else accuracy.append(0)\n",
    "            \n",
    "    acc_score = np.mean(accuracy)\n",
    "    print(\"Accuracy Score: {}\".format(acc_score))\n",
    "    \n",
    "    # calculate confusion metrix block\n",
    "    tags_name = sorted(set(test_tags))\n",
    "    c = len(tags_name) # Number of classes \n",
    "    confusion_metrix_ = np.zeros((c, c))\n",
    "\n",
    "    for i in range(len(test_tags)):\n",
    "        confusion_metrix_[tags_name.index(pred_tags[i])][tags_name.index(test_tags[i])] += 1\n",
    "\n",
    "    # write confusion metrix in a file\n",
    "    os.remove(output_file) if os.path.exists(output_file) else None # remove previouslt existing file\n",
    "    eval_file = open(output_file,\"w+\") # create new file\n",
    "    \n",
    "    for i in tqdm(range(0, len(tags_name))):\n",
    "        preds = confusion_metrix_[i]\n",
    "        true_false_positives = np.where(preds != 0)[0]\n",
    "        for index in true_false_positives:\n",
    "            eval_file.write(tags_name[i]+\" \"+tags_name[index]+\" : \"+str(int(preds[index]))+\" \\n\")\n",
    "    \n",
    "    print(\"Confusion Metrix Results are Write Successfuly in {} \\U0001f600 \\n\\n\".format(output_file.rsplit('/', 1)[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10e24b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tag_file = \"data/pos-key.txt\"\n",
    "pred_tag_file = \"data/pos-test-answers-0.txt\"\n",
    "output_file = 'data/pos-test-0-eval.txt'\n",
    "test_tags = read_tags(test_tag_file)\n",
    "pred_tags = read_tags(pred_tag_file)\n",
    "# evaluate_tags(output_file, test_tags, pred_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8134c00e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
