{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8fadc0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e39c36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will suppress any warnings, comment out if you'd like to preserve them\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcdcf1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check formatting of submissions\n",
    "def assertFloat(x):\n",
    "    assert type(float(x)) == float\n",
    "\n",
    "def assertFloatList(items, N):\n",
    "    assert len(items) == N\n",
    "    assert [type(float(x)) for x in items] == [float]*N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42a8d119",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "84568759",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"spoilers.json\", 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4b15a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for l in f:\n",
    "    d = eval(l)\n",
    "    dataset.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "043724ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23147241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A few utility data structures\n",
    "reviewsPerUser = defaultdict(list)\n",
    "reviewsPerItem = defaultdict(list)\n",
    "\n",
    "for d in dataset:\n",
    "    u,i = d['user_id'],d['book_id']\n",
    "    reviewsPerUser[u].append(d)\n",
    "    reviewsPerItem[i].append(d)\n",
    "\n",
    "# Sort reviews per user by timestamp\n",
    "for u in reviewsPerUser:\n",
    "    reviewsPerUser[u].sort(key=lambda x: x['timestamp'])\n",
    "    \n",
    "# Same for reviews per item\n",
    "for i in reviewsPerItem:\n",
    "    reviewsPerItem[i].sort(key=lambda x: x['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "742587d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2012-03-13',\n",
       " '2013-05-06',\n",
       " '2013-09-03',\n",
       " '2015-04-05',\n",
       " '2016-02-10',\n",
       " '2016-05-29']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# E.g. reviews for this user are sorted from earliest to most recent\n",
    "[d['timestamp'] for d in reviewsPerUser['b0d7e561ca59e313b728dc30a5b1862e']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "546b2080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5052"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviewsPerUser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "cf36f0b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'user_id': 'f51e2c1b6f20c9dbd2d448995e687388',\n",
       "  'timestamp': '2015-08-29',\n",
       "  'review_sentences': [[0,\n",
       "    \"While this is a solid entry in the series, it didn't quite have the magic of the previous couple of books.\"],\n",
       "   [0,\n",
       "    \"I am hoping against hope that that's not because Kate and Curran have finally gotten their relationship together.\"],\n",
       "   [0,\n",
       "    \"I found myself thinking of Jeaniene Frost's Night Huntress series when I was reading this one.\"],\n",
       "   [0, 'And not in a good way.'],\n",
       "   [0,\n",
       "    'I loved the first few books of that series, but, now that Cat and Bones are together (as are Kate and Curran), the series has become a little episodic (as was this book).'],\n",
       "   [0,\n",
       "    \"The writing is still good in both series, but I don't want to feel like I'm watching a TV series where each episode resolves a crime (or some such) with very little overarching plot.\"],\n",
       "   [0, \"It's early days for this series, so my fingers are crossed.\"]],\n",
       "  'rating': 4,\n",
       "  'has_spoiler': False,\n",
       "  'book_id': '8559047',\n",
       "  'review_id': 'dbc4f9ed8294059ccd14dac7e67c5742'}]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewsPerUser[user_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb364612",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "991fbe6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All ratings predcited Successfuly!\n"
     ]
    }
   ],
   "source": [
    "y = []\n",
    "y_pred = []\n",
    "user_ids = list(reviewsPerUser.keys())\n",
    "for user_id in user_ids:\n",
    "    user_ratings = reviewsPerUser[user_id]\n",
    "    if len(user_ratings) <2:\n",
    "        continue\n",
    "    actual_rating = reviewsPerUser[user_id][-1]['rating']\n",
    "    previous_ratings = [d['rating'] for d in reviewsPerUser[user_id][:-1]]\n",
    "    predicted_rating = sum(previous_ratings)/len(previous_ratings)\n",
    "    \n",
    "    y.append(actual_rating)\n",
    "    y_pred.append(predicted_rating)\n",
    "    \n",
    "print(\"All User ratings predcited Successfuly!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "942c4e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y_true, y_prediction):\n",
    "    MSE = np.square(np.subtract(y_true, y_prediction)).mean()\n",
    "    print(MSE)\n",
    "    return MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "373cff96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7686669082740192\n"
     ]
    }
   ],
   "source": [
    "answers['Q1a'] = MSE(y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bcd5ddd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q1a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38c9d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5131368a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Items rating predcited Successfuly!\n"
     ]
    }
   ],
   "source": [
    "y = []\n",
    "y_pred = []\n",
    "item_ids = list(reviewsPerItem.keys())\n",
    "for item_id in item_ids:\n",
    "    item_ratings = reviewsPerItem[item_id]\n",
    "    if len(item_ratings) <2:\n",
    "        continue\n",
    "    actual_rating = reviewsPerItem[item_id][-1]['rating']\n",
    "    previous_ratings = [d['rating'] for d in reviewsPerItem[item_id][:-1]]\n",
    "    predicted_rating = sum(previous_ratings)/len(previous_ratings)\n",
    "    \n",
    "    y.append(actual_rating)\n",
    "    y_pred.append(predicted_rating)\n",
    "    \n",
    "print(\"All Items rating predcited Successfuly!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2cccbe4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8881081920131038\n"
     ]
    }
   ],
   "source": [
    "answers['Q1b'] = MSE(y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7288fc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q1b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0abf5752",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bcd540f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.666035950804163\n",
      "2.015987909640471\n",
      "1.81504303599374\n"
     ]
    }
   ],
   "source": [
    "answers['Q2'] = []\n",
    "\n",
    "def predict_user_rating(N):\n",
    "    y = []\n",
    "    y_pred = []\n",
    "    user_ids = list(reviewsPerUser.keys())\n",
    "    for user_id in user_ids:\n",
    "        user_ratings = reviewsPerUser[user_id]\n",
    "        if len(user_ratings) < N+1:\n",
    "            continue\n",
    "        actual_rating = reviewsPerUser[user_id][-1]['rating']\n",
    "        previous_ratings = [d['rating'] for d in reviewsPerUser[user_id][-(N+1):-1]]\n",
    "        predicted_rating = sum(previous_ratings)/len(previous_ratings)\n",
    "\n",
    "        y.append(actual_rating)\n",
    "        y_pred.append(predicted_rating)\n",
    "\n",
    "    return y, y_pred\n",
    "\n",
    "for N in [1,2,3]:\n",
    "    y, y_pred = predict_user_rating(N)\n",
    "    answers['Q2'].append(MSE(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e1b4ed9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q2'], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206c058a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3ddd5e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature3(N, u): # For a user u and a window size of N\n",
    "    y = []\n",
    "    y_pred = []\n",
    "\n",
    "    user_ratings = reviewsPerUser[u]\n",
    "#     if len(user_ratings) < N+1:\n",
    "#         continue\n",
    "    actual_rating = reviewsPerUser[u][-1]['rating']\n",
    "    feature_vec = [d['rating'] for d in reviewsPerUser[u][-(N+1):]]\n",
    "    \n",
    "    return feature_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "05e622a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 4, 3]\n",
      "[4, 4, 4, 3]\n"
     ]
    }
   ],
   "source": [
    "answers['Q3a'] = [feature3(2,dataset[0]['user_id']), feature3(3,dataset[0]['user_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f839c5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(answers['Q3a']) == 2\n",
    "assert len(answers['Q3a'][0]) == 3\n",
    "assert len(answers['Q3a'][1]) == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55691b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4146d926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5608319121482543\n",
      "1.5409512373315701\n",
      "1.5396484853948416\n"
     ]
    }
   ],
   "source": [
    "answers['Q3b'] = []\n",
    "\n",
    "def get_previous_ratings(N):\n",
    "    X = []\n",
    "    y = []\n",
    "    user_ids = list(reviewsPerUser.keys())\n",
    "    for user_id in user_ids:\n",
    "        user_ratings = reviewsPerUser[user_id]\n",
    "        if len(user_ratings) < N+1:\n",
    "            continue\n",
    "        \n",
    "        next_rating = reviewsPerUser[user_id][-1]['rating']\n",
    "        feature_vec = [d['rating'] for d in reviewsPerUser[user_id][-(N+1):-1]]\n",
    "        \n",
    "        X.append(feature_vec)\n",
    "        y.append(next_rating)\n",
    "        \n",
    "    return X, y\n",
    "    \n",
    "for N in [1,2,3]:\n",
    "    X, y = get_previous_ratings(N)\n",
    "    \n",
    "    reg = linear_model.LinearRegression()\n",
    "    reg.fit(X, y)\n",
    "    y_pred = reg.predict(X)\n",
    "    \n",
    "    mse = MSE(y, y_pred)\n",
    "    answers['Q3b'].append(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d512b24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q3b'], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba65fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4aab34e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "globalAverage = [d['rating'] for d in dataset]\n",
    "globalAverage = sum(globalAverage) / len(globalAverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "2676be3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureMeanValue(N, u): # For a user u and a window size of N\n",
    "    user_ratings = reviewsPerUser[u]\n",
    "    if len(user_ratings) < 1:\n",
    "        feature_vec = [globalAverage] * 11\n",
    "    elif len(user_ratings) > 11:\n",
    "        feature_vec = [d['rating'] for d in reviewsPerUser[u][-11:]]\n",
    "    else:\n",
    "        feature_vec = [d['rating'] for d in reviewsPerUser[u]]\n",
    "        \n",
    "        missing_index = 11 - len(feature_vec)\n",
    "        avg_user_rating = sum(feature_vec)/len(feature_vec)\n",
    "        missing_values = [avg_user_rating] * missing_index\n",
    "        feature_vec = missing_values + feature_vec\n",
    "\n",
    "    return feature_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "270cf89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureMissingValue(N, u):\n",
    "    user_ratings = reviewsPerUser[u]\n",
    "    if len(user_ratings) < 1:\n",
    "        feature_vec = [1 ,0] * 10\n",
    "    elif len(user_ratings) > 10:\n",
    "        feature_vec = []\n",
    "        for d in reviewsPerUser[u][-11:-1]:\n",
    "            feature_vec.append(0)\n",
    "            feature_vec.append(d['rating'])\n",
    "        feature_vec.append(reviewsPerUser[u][-1]['rating'])\n",
    "    else:\n",
    "        feature_vec = []\n",
    "        for d in reviewsPerUser[u][:-1]:\n",
    "            feature_vec.append(0)\n",
    "            feature_vec.append(d['rating'])\n",
    "\n",
    "        feature_vec.append(reviewsPerUser[u][-1]['rating'])\n",
    "        missing_index = 11 - len(user_ratings)\n",
    "        missing_values = [1 ,0] * missing_index\n",
    "        feature_vec = missing_values + feature_vec\n",
    "        \n",
    "    return feature_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "58791bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q4a'] = [featureMeanValue(10, dataset[0]['user_id']), featureMissingValue(10, dataset[0]['user_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "a3c28e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(answers['Q4a']) == 2\n",
    "assert len(answers['Q4a'][0]) == 11\n",
    "assert len(answers['Q4a'][1]) == 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "cbcee03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "73fabbf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9601498490565842\n",
      "9.759098376880443\n"
     ]
    }
   ],
   "source": [
    "answers['Q4b'] = []\n",
    "\n",
    "for featFunc in [featureMeanValue, featureMissingValue]:\n",
    "    y = []\n",
    "    y_pred = []\n",
    "    user_ids = list(reviewsPerUser.keys())\n",
    "    for user_id in user_ids:\n",
    "        feature_vec = featFunc(10, user_id)\n",
    "        y.append(feature_vec.pop())\n",
    "#         print(feature_vec)\n",
    "        prediction = sum(feature_vec)/len(feature_vec)\n",
    "        y_pred.append(prediction)\n",
    "    mse = MSE(y, y_pred)\n",
    "    answers['Q4b'].append(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "e348489b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers[\"Q4b\"], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c548e8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "1cee7eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature5(sentence):\n",
    "    char_len = len(sentence) - sentence.count(' ')\n",
    "    exclamation_len =  sentence.count('!')\n",
    "    uppen_char_len =  sum(1 for s in sentence if s.isupper())\n",
    "    \n",
    "    return [char_len, exclamation_len, uppen_char_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "426ca2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "X = []\n",
    "\n",
    "for d in dataset:\n",
    "    for spoiler,sentence in d['review_sentences']:\n",
    "        X.append(feature5(sentence))\n",
    "        y.append(spoiler)\n",
    "        \n",
    "log_reg = linear_model.LogisticRegression(class_weight='balanced', C=1)\n",
    "log_reg.fit(X, y)\n",
    "y_pred = log_reg.predict(np.array(X))\n",
    "\n",
    "\n",
    "TP = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "FN = 0\n",
    "\n",
    "for i in range(len(y_pred)): \n",
    "    if y[i]==y_pred[i]==1:\n",
    "       TP += 1\n",
    "    if y_pred[i]==1 and y[i]!=y_pred[i]:\n",
    "       FP += 1\n",
    "    if y[i]==y_pred[i]==0:\n",
    "       TN += 1\n",
    "    if y_pred[i]==0 and y[i]!=y_pred[i]:\n",
    "       FN += 1\n",
    "    \n",
    "TPR = TP / (TP + FN)\n",
    "TNR = TN / (TN + FP)\n",
    "\n",
    "balanced_accuracy = (TPR + TNR) / 2\n",
    "BER = 1 - balanced_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "a94d7aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q5a'] = X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "116c5b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q5b'] = [TP, TN, FP, FN, BER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "c0c96525",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(answers['Q5a']) == 3\n",
    "assertFloatList(answers['Q5b'], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f826e166",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193e94e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature6(review):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a437dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "X = []\n",
    "\n",
    "for d in dataset:\n",
    "    sentences = d['review_sentences']\n",
    "    if len(sentences) < 6: continue\n",
    "    X.append(feature6(d))\n",
    "    y.append(sentences[5][0])\n",
    "\n",
    "#etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61a5fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q6a'] = X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f977c642",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q6b'] = BER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0be28cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(answers['Q6a']) == 9\n",
    "assertFloat(answers['Q6b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bda0b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c01c5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50/25/25% train/valid/test split\n",
    "Xtrain, Xvalid, Xtest = X[:len(X)//2], X[len(X)//2:(3*len(X))//4], X[(3*len(X))//4:]\n",
    "ytrain, yvalid, ytest = y[:len(X)//2], y[len(X)//2:(3*len(X))//4], y[(3*len(X))//4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c253fc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in [0.01, 0.1, 1, 10, 100]:\n",
    "    # etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8389608",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q7'] = bers + [bestC] + [ber]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d53b5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q7'], 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06e4f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a6c14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    if denom == 0:\n",
    "        return 0\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f30ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 75/25% train/test split\n",
    "dataTrain = dataset[:15000]\n",
    "dataTest = dataset[15000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d770bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A few utilities\n",
    "\n",
    "itemAverages = defaultdict(list)\n",
    "ratingMean = []\n",
    "\n",
    "for d in dataTrain:\n",
    "    itemAverages[d['book_id']].append(d['rating'])\n",
    "    ratingMean.append(d['rating'])\n",
    "\n",
    "for i in itemAverages:\n",
    "    itemAverages[i] = sum(itemAverages[i]) / len(itemAverages[i])\n",
    "\n",
    "ratingMean = sum(ratingMean) / len(ratingMean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62952595",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewsPerUser = defaultdict(list)\n",
    "usersPerItem = defaultdict(set)\n",
    "\n",
    "for d in dataTrain:\n",
    "    u,i = d['user_id'], d['book_id']\n",
    "    reviewsPerUser[u].append(d)\n",
    "    usersPerItem[i].add(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0ab533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From my HW2 solution, welcome to reuse\n",
    "def predictRating(user,item):\n",
    "    ratings = []\n",
    "    similarities = []\n",
    "    for d in reviewsPerUser[user]:\n",
    "        i2 = d['book_id']\n",
    "        if i2 == item: continue\n",
    "        ratings.append(d['rating'] - itemAverages[i2])\n",
    "        similarities.append(Jaccard(usersPerItem[item],usersPerItem[i2]))\n",
    "    if (sum(similarities) > 0):\n",
    "        weightedRatings = [(x*y) for x,y in zip(ratings,similarities)]\n",
    "        return itemAverages[item] + sum(weightedRatings) / sum(similarities)\n",
    "    else:\n",
    "        # User hasn't rated any similar items\n",
    "        if item in itemAverages:\n",
    "            return itemAverages[item]\n",
    "        else:\n",
    "            return ratingMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0e1d97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4891766",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers[\"Q8\"] = MSE(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789b53e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers[\"Q8\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b298ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5930c59a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b8ce68",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dataTest:\n",
    "    # etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2a4664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d269238e",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers[\"Q9\"] = [mse0, mse1to5, mse5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfff50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers[\"Q9\"], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbe10f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fea856",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305d3531",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers[\"Q10\"] = (\"describe your solution\", itsMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0613500",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert type(answers[\"Q10\"][0]) == str\n",
    "assertFloat(answers[\"Q10\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436d2691",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"answers_midterm.txt\", 'w')\n",
    "f.write(str(answers) + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53acc41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
