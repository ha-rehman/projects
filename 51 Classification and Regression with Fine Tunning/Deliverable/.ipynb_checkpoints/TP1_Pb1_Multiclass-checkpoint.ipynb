{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-classification problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the next line to install packages\n",
    "# !pip install torch torchvision matplotlib pandas seaborn requests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import requests\n",
    "import os\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "PyTorch provides two powerful data primitives: `torch.utils.data.DataLoader` and `torch.utils.data.Dataset` that allow you to use pre-loaded datasets as well as prepare your own data. `Dataset` stores the samples and their corresponding labels, and `DataLoader` wraps an iterable around the Dataset to enable easy access to the samples.\n",
    "\n",
    "### USPS Dataset\n",
    "* Handwritten digits with 10 classes\n",
    "* 16x16 pixels for each image \n",
    "* 6 000 data examples in training set, 1 291 examples in validation set, 2 007 in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/usps.bz2'\n",
    "r = requests.get(url, allow_redirects=True)\n",
    "if not os.path.isdir('USPS/'):\n",
    "    os.mkdir('USPS/')\n",
    "open('USPS/usps.bz2', 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading USPS dataset from torchvision.dataset\n",
    "dataset = torchvision.datasets.USPS(root='USPS/',\n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),\n",
    "                                           download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset USPS\n",
       "    Number of datapoints: 7291\n",
       "    Root location: USPS/\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get info from dataset\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the inputs and targets:\n",
    "inputs = dataset.data\n",
    "targets = dataset.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample type and shape :  <class 'numpy.ndarray'> (16, 16)\n",
      "Label type and value :  <class 'int'> 9\n"
     ]
    }
   ],
   "source": [
    "# Let's look at a data point\n",
    "sample_index = 88\n",
    "\n",
    "data_sample = dataset.data[sample_index]\n",
    "target_sample = dataset.targets[sample_index]\n",
    "print(\"Sample type and shape : \",type(data_sample),data_sample.shape)\n",
    "print(\"Label type and value : \" ,type(target_sample),target_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_index = 88\n",
    "plt.imshow(dataset.data[sample_index], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "plt.title(\"image label: %d\" % dataset.targets[sample_index])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch Documentation : https://pytorch.org/docs/stable/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor type : <class 'torch.Tensor'> , and shape :  torch.Size([16, 16])\n"
     ]
    }
   ],
   "source": [
    "tensor_data_point = torch.tensor(data_sample)\n",
    "print(\"Tensor type :\",type(tensor_data_point),\", and shape : \",tensor_data_point.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Pyplot can manage torch Tensors\n",
    "plt.imshow(tensor_data_point, cmap=plt.cm.gray_r)\n",
    "plt.title(\"Tensor display\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset to training and validation sets\n",
    "train_set, val_set = random_split(dataset, [6000, 1291])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build your Neural Network\n",
    "The `torch.nn` namespace provides all the building blocks you need to create your own neural network such as fully connected layers or convolutional layers etc. We define our neural network by subclassing `nn.Module`, and the neural network layers are initialized in **\\__init\\__**. Every `nn.Module` subclass implements the operations on input data in the **forward** method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inheritance in Python (https://www.programiz.com/python-programming/inheritance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base model\n",
    "class base_Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, activation, hidden_size):\n",
    "        super().__init__()\n",
    "        # We allocate space for the weights\n",
    "        self.l1 = nn.Linear(16*16, hidden_size)\n",
    "        self.l2 = nn.Linear(hidden_size, 10)\n",
    "        self.activation = activation\n",
    "        # Input size is 16*16, output size should be the same with the number of classes\n",
    "        \n",
    "    def forward(self, inputs): # Called when we apply the network \n",
    "        h = self.activation(self.l1(inputs)) # You can put anything, as long as its Pytorch functions\n",
    "        outputs = F.softmax(self.l2(h), dim=1)# Use softmax as the activation function for the last layer\n",
    "        return outputs\n",
    "    \n",
    "\n",
    "class custmize_Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, activation, hidden_size):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, 10)\n",
    "        self.activation = activation\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = self.activation(self.conv2(x))\n",
    "#         x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 64 * 8 * 8)\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function for training\n",
    "def train(num_epochs, batch_size, criterion, optimizer, model, dataset):\n",
    "    train_error = []\n",
    "    train_accuracy = []\n",
    "    train_loader = DataLoader(dataset, batch_size, shuffle=True)\n",
    "    model.train() # Indicates to the network we are in training mode\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_average_loss = 0.0\n",
    "        correct = 0\n",
    "        for (images, labels) in train_loader:\n",
    "            y_pre = model(images.view(batch_size, -1)) \n",
    "            #reshape the inputs from [N, img_shape, img_shape] to [N, img_shape*img_shape] \n",
    "            \n",
    "            # One-hot encoding or labels so as to calculate MSE error:\n",
    "            labels_one_hot = torch.FloatTensor(batch_size, 10)\n",
    "            labels_one_hot.zero_()\n",
    "            labels_one_hot.scatter_(1, labels.view(-1, 1), 1)\n",
    "\n",
    "            # calculate acuracy\n",
    "            _, predicted = torch.max(y_pre, 1) \n",
    "            correct += (predicted==labels).sum()\n",
    "\n",
    "            # calculate and backpropagate loss\n",
    "            loss = criterion(y_pre, labels_one_hot) if str(criterion) == \"MSELoss()\" else criterion(y_pre, labels) #Real number\n",
    "            optimizer.zero_grad() # Set all the parameters gradient to 0\n",
    "            loss.backward() # Computes  dloss/da for every parameter a which has requires_grad=True\n",
    "            optimizer.step() # Updates the weights \n",
    "            epoch_average_loss += loss.item() * batch_size / len(dataset)\n",
    "            \n",
    "            \n",
    "        train_accuracy.append(100 * correct.item()/len(dataset))\n",
    "        train_error.append(epoch_average_loss)\n",
    "\n",
    "    return sum(train_accuracy)/len(train_accuracy)\n",
    "\n",
    "\n",
    "# define a function for training\n",
    "def train2(num_epochs, batch_size, criterion, optimizer, model, dataset):\n",
    "    train_error = []\n",
    "    train_accuracy = []\n",
    "    train_loader = DataLoader(dataset, batch_size, shuffle=True)\n",
    "    model.train() # Indicates to the network we are in training mode\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_average_loss = 0.0\n",
    "        correct = 0\n",
    "        for (images, labels) in train_loader:\n",
    "            y_pre = model(images) \n",
    "            #reshape the inputs from [N, img_shape, img_shape] to [N, img_shape*img_shape] \n",
    "            \n",
    "            # One-hot encoding or labels so as to calculate MSE error:\n",
    "            labels_one_hot = torch.FloatTensor(batch_size, 10)\n",
    "            labels_one_hot.zero_()\n",
    "            labels_one_hot.scatter_(1, labels.view(-1, 1), 1)\n",
    "\n",
    "            # calculate acuracy\n",
    "            _, predicted = torch.max(y_pre, 1) \n",
    "            correct += (predicted==labels).sum()\n",
    "\n",
    "            # calculate and backpropagate loss\n",
    "            loss = criterion(y_pre, labels_one_hot) if str(criterion) == \"MSELoss()\" else criterion(y_pre, labels) #Real number\n",
    "            optimizer.zero_grad() # Set all the parameters gradient to 0\n",
    "            loss.backward() # Computes  dloss/da for every parameter a which has requires_grad=True\n",
    "            optimizer.step() # Updates the weights \n",
    "            epoch_average_loss += loss.item() * batch_size / len(dataset)\n",
    "            \n",
    "        \n",
    "        train_accuracy.append(100 * correct.item()/len(dataset))\n",
    "        train_error.append(epoch_average_loss)\n",
    "\n",
    "    return sum(train_accuracy)/len(train_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description of AutoGrad (https://pytorch.org/docs/stable/notes/autograd.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 28.65\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 42.51\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 16.29\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 31.94\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 12.17\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 29.25\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 93.81\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 90.93\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 94.57\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 89.36\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 94.95\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 90.41\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 93.95\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 80.9\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 93.67\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 85.77\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 93.55\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 91.68\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 6.78\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 14.88\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 12.75\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 7.16\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 7.31\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 10.3\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 94.49\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 92.31\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 93.94\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 92.35\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 93.74\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 84.22\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 77.55\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 64.63\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 79.93\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 62.51\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 75.16\n",
      "=========================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 65.07\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 7.63\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 1.88\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 12.37\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 10.07\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 13.65\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 16.09\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 86.33\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 77.6\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 82.72\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 70.65\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 78.75\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 67.7\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 31.48\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 24.85\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 43.34\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 34.06\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 33.86\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 33.76\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 22.52\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 46.02\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 26.58\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 31.52\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 26.99\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 31.36\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 93.86\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 91.63\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 94.56\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 92.78\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 94.9\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 93.53\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 94.85\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 83.31\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 94.42\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 87.16\n",
      "=========================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 94.44\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 92.45\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 13.3\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 29.9\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 9.86\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 16.81\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 12.17\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 19.97\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 95.34\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 92.23\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 94.71\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 86.33\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 94.13\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 92.02\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 85.51\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 71.95\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 83.2\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 71.38\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 81.37\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 69.99\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 19.05\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 5.3\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 2.67\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 4.02\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 9.44\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 8.44\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 88.74\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 81.6\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 85.69\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 77.93\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 83.25\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 72.47\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 29.32\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 30.89\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 35.06\n",
      "=========================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 27.76\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 38.3\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 41.83\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 29.74\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 48.98\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 18.91\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 31.77\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 16.15\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 25.94\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 93.37\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 67.24\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 94.35\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 84.11\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 94.52\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 83.89\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 95.42\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 94.48\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 95.23\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 85.21\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 95.2\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 86.05\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 11.54\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 15.72\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 7.88\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 23.85\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 6.87\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 13.58\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 95.98\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 91.96\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 95.34\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 91.76\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 95.09\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 93.28\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 88.63\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 79.93\n",
      "=========================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 86.73\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 77.92\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 86.91\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 73.61\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 10.99\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 7.56\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 0.71\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 9.79\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 10.35\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 9.94\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 91.19\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 82.31\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 88.55\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 79.5\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 86.42\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 78.61\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 39.63\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 32.17\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 43.83\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 30.74\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 34.11\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 27.84\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 31.54\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 46.9\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 28.23\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 35.3\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 30.32\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 26.75\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 93.16\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 93.49\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 94.71\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 93.54\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 95.18\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 94.78\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 94.5\n",
      "=========================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 93.67\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 94.39\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 93.39\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 94.17\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 92.88\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 10.26\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 19.02\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 8.11\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 22.48\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 5.07\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 23.15\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 95.4\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 94.2\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 94.51\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 93.08\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 93.65\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 92.24\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 78.13\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 65.15\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 76.05\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 60.75\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 75.77\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 60.13\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 6.12\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 13.89\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 13.23\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 8.25\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 7.77\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 7.64\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 86.85\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 80.9\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 82.8\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 74.45\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 79.93\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 68.16\n",
      "=========================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 30.45\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 30.79\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 32.84\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 30.34\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 30.84\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 26.26\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 32.02\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 51.97\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 24.22\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 39.54\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 25.6\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 32.74\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 91.86\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 92.4\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 93.58\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 93.83\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 94.39\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 94.31\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 94.97\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 94.45\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 95.09\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 94.31\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 94.77\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 94.07\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 25.75\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 27.04\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 12.6\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 19.23\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 7.39\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 24.94\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 95.43\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 94.7\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 95.03\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 94.08\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 94.43\n",
      "=========================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 93.36\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 84.78\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 75.42\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 83.17\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 69.97\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 81.98\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 67.39\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 8.87\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 10.04\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 1.1\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 4.72\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 11.48\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 7.29\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 89.08\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 85.09\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 86.45\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 80.34\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 84.14\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 76.94\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 33.23\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 30.57\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 35.31\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 24.33\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 31.69\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 25.14\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 28.14\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 57.02\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 25.77\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 42.63\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 22.11\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 33.88\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 88.32\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 77.16\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 91.86\n",
      "=========================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 92.7\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 92.72\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 93.1\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 95.28\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 94.72\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 95.05\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 94.75\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 94.86\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 94.7\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 14.85\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 27.64\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 18.96\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 15.2\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 19.09\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 12.59\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 95.31\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 94.87\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 95.08\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 94.47\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 94.93\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 93.94\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 88.91\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 83.47\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 88.11\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 79.75\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 86.66\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 77.81\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 1.89\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 19.07\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 10.09\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 11.37\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 15.02\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 12.37\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 91.21\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 88.19\n",
      "=========================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 88.73\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 85.38\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 86.79\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 80.32\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 40.17\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 32.23\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 38.63\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 30.41\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 36.91\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 27.23\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 15.94\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 24.15\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 13.41\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 22.36\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 15.02\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 15.28\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 95.66\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 94.54\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 95.99\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 94.63\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 95.79\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 93.95\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 90.75\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 80.54\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 90.36\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 77.33\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 89.69\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 76.52\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 7.05\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 20.92\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 14.08\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 16.01\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 8.88\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 8.87\n",
      "=========================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 92.45\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 86.97\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 90.41\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 81.38\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 88.88\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 80.68\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 44.35\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 35.42\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 40.0\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 31.51\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 38.31\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 29.87\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 7.33\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 8.87\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 16.28\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 14.08\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 9.22\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 9.35\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 67.65\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 52.06\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 58.93\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 42.7\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 50.82\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 37.39\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 23.19\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 17.75\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 16.28\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 21.98\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 18.34\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 16.24\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 16.62\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 26.73\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 16.28\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 23.39\n",
      "=========================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 16.01\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 20.15\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 95.49\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 94.31\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 95.84\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 93.97\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 95.74\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 93.98\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 92.39\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 85.07\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 91.99\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 80.96\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 91.26\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 77.58\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 16.28\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 15.65\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 12.8\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 16.28\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 7.51\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 16.28\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 93.33\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 90.99\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 91.81\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 85.57\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 90.73\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 83.32\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 55.52\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 39.63\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 47.7\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 37.0\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 46.43\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 36.81\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 7.57\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 16.3\n",
      "=========================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 8.88\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 8.98\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 7.35\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 14.08\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 75.36\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 61.88\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 66.6\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 49.98\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 59.45\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 43.79\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 24.04\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 27.45\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 27.33\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 16.29\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 18.79\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 30.49\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 21.17\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 27.69\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 16.29\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 26.26\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 15.79\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 24.55\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 95.17\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 90.66\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 95.33\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 93.37\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 95.58\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 82.52\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 93.15\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 87.82\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 92.62\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 85.98\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 92.26\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 86.79\n",
      "=========================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 12.26\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 16.02\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 9.97\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 15.31\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 9.22\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 10.0\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 94.0\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 90.62\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 92.66\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 84.82\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 91.87\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 85.42\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 63.14\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 45.53\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 59.8\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 43.66\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 57.66\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 41.82\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 9.22\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 10.0\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 9.22\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 9.12\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 14.82\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 13.93\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 80.43\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 64.96\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 73.5\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 55.65\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 68.32\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 49.53\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 26.01\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 17.85\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 27.23\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 29.19\n",
      "=========================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 29.68\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 16.31\n",
      "=========================================\n",
      "\n",
      "Best Hyper parameters for Classification Model\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'best_params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 39\u001b[0m\n\u001b[0;32m     34\u001b[0m                             base_best_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivation\u001b[39m\u001b[38;5;124m'\u001b[39m: activation, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: learning_rate,\n\u001b[0;32m     35\u001b[0m                                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m'\u001b[39m: optimizer_class, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhiden_size\u001b[39m\u001b[38;5;124m'\u001b[39m: hiden_size,\n\u001b[0;32m     36\u001b[0m                                           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m: batch_size, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m: loss}\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Hyper parameters for Classification Model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mbest_params\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_params' is not defined"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'activation': [torch.nn.ReLU(), torch.nn.Tanh(), torch.nn.Sigmoid()],\n",
    "    'learning_rate': [0.01, 0.001, 0.0001],\n",
    "    'batch_size': [10, 20, 30],\n",
    "    'hiden_size': [64, 128, 256],\n",
    "    'optimizer': [optim.SGD, optim.Adam, optim.Adagrad],\n",
    "    'loss': [nn.MSELoss(), nn.CrossEntropyLoss()]\n",
    "}\n",
    "\n",
    "epochs = 10\n",
    "base_best_acc = -np.inf\n",
    "base_best_params = None\n",
    "\n",
    "for activation in param_grid['activation']:\n",
    "    for hiden_size in param_grid['hiden_size']:\n",
    "        for learning_rate in param_grid['learning_rate']:\n",
    "            for optimizer_class in param_grid['optimizer']:\n",
    "                for batch_size in param_grid['batch_size']:\n",
    "                    for loss in param_grid['loss']:\n",
    "                        # Create the model: \n",
    "                        model = base_Model(activation, hiden_size)\n",
    "                        optimizer = optimizer_class(model.parameters(), lr=learning_rate)\n",
    "                        train_accuracy = train(epochs, batch_size, loss, optimizer, model, train_set)\n",
    "                        train_accuracy = float(\"{:.2f}\".format(train_accuracy))\n",
    "                        \n",
    "                        print(\"Hyper Parameters: activation-function: {}, hiden-size: {}, learning-rate: {}, optmizer: {}, batch-size: {}, loss-function: {}\".\n",
    "                              format(activation, hiden_size, learning_rate, str(optimizer_class), batch_size, loss))\n",
    "                        print(\"Accuracy Score: {}\".format(train_accuracy))\n",
    "                        print(\"=========================================\\n\")\n",
    "                        \n",
    "                        # Update the best hyperparameters and accuracy\n",
    "                        if train_accuracy > base_best_acc:\n",
    "                            base_best_acc = train_accuracy\n",
    "                            base_best_params = {'activation': activation, 'learning_rate': learning_rate,\n",
    "                                           'optimizer': optimizer_class, 'hiden_size': hiden_size,\n",
    "                                          'batch_size': batch_size, 'loss': loss}\n",
    "\n",
    "print(\"Best Hyper parameters for Classification Model\")\n",
    "print(base_best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Customize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 77.55\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 90.94\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 70.22\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 88.71\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 55.61\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 82.38\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 95.77\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 16.06\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 15.71\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 96.86\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 93.71\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 95.82\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 97.54\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 97.01\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 93.59\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 97.1\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 93.11\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 97.06\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 29.93\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 65.44\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 28.8\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 43.4\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 19.64\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 29.89\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 98.85\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 97.17\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 98.45\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 96.91\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 97.96\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 96.39\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 93.11\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 90.51\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 92.2\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 89.63\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 92.04\n",
      "=========================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 89.52\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 18.31\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 24.1\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 16.3\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 16.37\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 12.78\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 15.55\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 95.55\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 92.56\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 94.17\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 91.08\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 93.29\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 90.04\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 79.96\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 63.67\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 77.18\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 48.16\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 74.97\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 45.3\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 73.12\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 91.35\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 70.36\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 86.72\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 61.76\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 85.49\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 96.53\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 95.26\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 96.2\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 97.4\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 90.67\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 96.02\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 97.17\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 97.1\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 94.44\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 97.38\n",
      "=========================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 94.69\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 97.03\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 32.51\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 66.6\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 29.31\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 45.28\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 24.66\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 23.22\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 98.94\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 97.65\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 98.61\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 97.28\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 98.35\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 97.0\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 95.31\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 92.32\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 94.98\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 91.3\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 94.02\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 91.62\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 16.44\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 15.75\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 10.9\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 17.37\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 3.84\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 15.98\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 96.29\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 93.47\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 95.4\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 92.09\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 94.2\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 90.38\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 84.69\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 68.14\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 81.13\n",
      "=========================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 64.77\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 76.89\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 68.55\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 80.15\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 90.23\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 74.32\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 87.87\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 62.56\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 84.36\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 96.64\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 95.07\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 95.72\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 96.26\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 15.74\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 96.61\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 96.72\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 97.8\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 96.78\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 97.5\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 95.05\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 97.07\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 33.34\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 69.45\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 29.45\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 49.61\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 25.75\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 30.14\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 98.98\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 97.94\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 98.73\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 97.67\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 98.55\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 97.48\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 96.08\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 92.98\n",
      "=========================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 95.63\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 92.63\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 95.03\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 92.54\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 16.95\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 16.17\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 16.12\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 16.38\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 17.79\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 9.13\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 97.04\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 94.48\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 96.14\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 93.05\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 95.28\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 91.45\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 85.96\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 75.71\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 82.45\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 72.63\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 83.77\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: ReLU(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 71.24\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 83.68\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 92.41\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 79.42\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 88.61\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 76.48\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 86.61\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 11.32\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 76.52\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 11.45\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 86.72\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 11.73\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 87.31\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 19.27\n",
      "=========================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 96.92\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 14.98\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 81.12\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 15.08\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 95.88\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 51.15\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 73.84\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 43.78\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 56.19\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 32.27\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 40.55\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 97.78\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 97.29\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 97.27\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 97.08\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 96.91\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 96.89\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 92.91\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 93.27\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 93.37\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 92.99\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 92.59\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 92.47\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 25.0\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 23.87\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 17.93\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 24.82\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 8.21\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 19.23\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 95.54\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 94.49\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 94.04\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 93.37\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 93.08\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 92.08\n",
      "=========================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 84.22\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 71.98\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 83.93\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 67.62\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 82.01\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 68.03\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 82.39\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 93.06\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 80.49\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 89.67\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 73.75\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 86.35\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 11.04\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 82.31\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 11.27\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 84.99\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 11.51\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 89.53\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 27.83\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 97.19\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 90.47\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 97.58\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 85.33\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 96.81\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 57.91\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 69.07\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 46.86\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 58.11\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 37.65\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 43.97\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 97.72\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 97.59\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 97.32\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 97.54\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 96.77\n",
      "=========================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 97.46\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 93.91\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 94.34\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 92.03\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 93.9\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 92.37\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 93.28\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 27.05\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 29.19\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 18.51\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 19.08\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 8.01\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 16.41\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 95.59\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 95.19\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 94.74\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 94.13\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 93.29\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 93.06\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 85.77\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 76.73\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 85.32\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 76.01\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 84.58\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 73.97\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 84.71\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 92.76\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 78.41\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 89.48\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 72.66\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 87.12\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 10.86\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 82.64\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 11.11\n",
      "=========================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 84.24\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 10.93\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 90.01\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 13.07\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 98.3\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 12.8\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 98.21\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 13.22\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 93.31\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 51.93\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 73.64\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 40.32\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 56.3\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 38.89\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 51.39\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 97.45\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 97.74\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 97.43\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 97.89\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 96.62\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 97.82\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 94.35\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 94.71\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 93.7\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 94.17\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 92.87\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 94.09\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 27.54\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 27.26\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 17.82\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 29.86\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 13.35\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 21.21\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 95.67\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 95.98\n",
      "=========================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 94.75\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 95.19\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 94.47\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 93.92\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 86.81\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 82.26\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 87.94\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 80.24\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 87.09\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Tanh(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 77.81\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 15.87\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 16.35\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 16.05\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 16.22\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 16.14\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 16.17\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 11.48\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 13.93\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 12.6\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 14.27\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 12.54\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 14.91\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 15.63\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 16.23\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 15.83\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 16.23\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 15.76\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 16.25\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 15.83\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 16.15\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 15.4\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 16.13\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 15.5\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 15.89\n",
      "=========================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 91.19\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 91.17\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 85.9\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 88.48\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 82.45\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 85.52\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 28.94\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 32.13\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 34.55\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 29.29\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 29.25\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 24.6\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 11.55\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 15.97\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 8.37\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 13.93\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 8.88\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 12.49\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 69.72\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 68.47\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 60.12\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 58.49\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 48.67\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 50.18\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 16.3\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 16.27\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 16.22\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 16.28\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 16.16\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 64, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 16.2\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 16.23\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 16.22\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 15.9\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 16.18\n",
      "=========================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 16.29\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 16.12\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 11.61\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 12.64\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 11.69\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 12.97\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 12.32\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 13.37\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 15.21\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 16.19\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 15.19\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 16.12\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 15.67\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 16.06\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 16.12\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 16.26\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 16.22\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 15.95\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 15.89\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 16.07\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 83.88\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 90.23\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 83.53\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 87.88\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 82.06\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 84.57\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 37.44\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 35.17\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 29.57\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 39.01\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 24.31\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 29.43\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 15.21\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 14.91\n",
      "=========================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 10.33\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 15.85\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 13.38\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 12.64\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 71.98\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 71.66\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 59.94\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 60.7\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 48.77\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 57.59\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 16.45\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 16.26\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 16.64\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 16.27\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 16.3\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 128, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 16.26\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 15.15\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 16.12\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 15.89\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 16.09\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 15.76\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 15.95\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 11.19\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 12.16\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 11.43\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 12.2\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 11.7\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 12.7\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 14.32\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 15.89\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 14.58\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 15.81\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 15.01\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.01, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 15.94\n",
      "=========================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 15.95\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 16.16\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 16.23\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 16.11\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 16.11\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 16.28\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 89.81\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 89.02\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 83.78\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 88.32\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 81.15\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 87.13\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 39.45\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 49.16\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 30.1\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 38.33\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 21.9\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 29.02\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 14.06\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 15.37\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 12.04\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 14.48\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 16.28\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.sgd.SGD'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 15.49\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 71.34\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 74.21\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 65.86\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 66.84\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 57.25\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adam.Adam'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 59.51\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: MSELoss()\n",
      "Accuracy Score: 16.48\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 10, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 16.26\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: MSELoss()\n",
      "Accuracy Score: 16.49\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 20, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 16.25\n",
      "=========================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: MSELoss()\n",
      "Accuracy Score: 16.88\n",
      "=========================================\n",
      "\n",
      "Hyper Parameters: activation-function: Sigmoid(), hiden-size: 256, learning-rate: 0.0001, optmizer: <class 'torch.optim.adagrad.Adagrad'>, batch-size: 30, loss-function: CrossEntropyLoss()\n",
      "Accuracy Score: 16.21\n",
      "=========================================\n",
      "\n",
      "Best Hyper parameters for Classification Model\n",
      "{'activation': ReLU(), 'learning_rate': 0.001, 'optimizer': <class 'torch.optim.adam.Adam'>, 'hiden_size': 256, 'batch_size': 10, 'loss': MSELoss()}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'activation': [torch.nn.ReLU(), torch.nn.Tanh(), torch.nn.Sigmoid()],\n",
    "    'learning_rate': [0.01, 0.001, 0.0001],\n",
    "    'batch_size': [10, 20, 30],\n",
    "    'hiden_size': [64, 128, 256],\n",
    "    'optimizer': [optim.SGD, optim.Adam, optim.Adagrad],\n",
    "    'loss': [nn.MSELoss(), nn.CrossEntropyLoss()]\n",
    "}\n",
    "\n",
    "epochs = 10\n",
    "custom_best_acc = -np.inf\n",
    "custom_best_params = None\n",
    "\n",
    "for activation in param_grid['activation']:\n",
    "    for hiden_size in param_grid['hiden_size']:\n",
    "        for learning_rate in param_grid['learning_rate']:\n",
    "            for optimizer_class in param_grid['optimizer']:\n",
    "                for batch_size in param_grid['batch_size']:\n",
    "                    for loss in param_grid['loss']:\n",
    "                        # Create the model: \n",
    "                        model = custmize_Model(activation, hiden_size)\n",
    "                        optimizer = optimizer_class(model.parameters(), lr=learning_rate)\n",
    "                        train_accuracy = train2(epochs, batch_size, loss, optimizer, model, train_set)\n",
    "                        train_accuracy = float(\"{:.2f}\".format(train_accuracy))\n",
    "                        \n",
    "                        print(\"Hyper Parameters: activation-function: {}, hiden-size: {}, learning-rate: {}, optmizer: {}, batch-size: {}, loss-function: {}\".\n",
    "                              format(activation, hiden_size, learning_rate, str(optimizer_class), batch_size, loss))\n",
    "                        print(\"Accuracy Score: {}\".format(train_accuracy))\n",
    "                        print(\"=========================================\\n\")\n",
    "                        \n",
    "                        # Update the best hyperparameters and accuracy\n",
    "                        if train_accuracy > custom_best_acc:\n",
    "                            custom_best_acc = train_accuracy\n",
    "                            custom_best_params = {'activation': activation, 'learning_rate': learning_rate,\n",
    "                                           'optimizer': optimizer_class, 'hiden_size': hiden_size,\n",
    "                                          'batch_size': batch_size, 'loss': loss}\n",
    "\n",
    "                            \n",
    "print(\"Best Hyper parameters for Classification Model\")\n",
    "print(custom_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Accuracy on best parameters\n",
      "98.98\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMaximum Accuracy on best parameters\")\n",
    "print(custom_best_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Best Params with Different Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "_params = base_best_params if base_best_acc > custom_best_acc else custom_best_params\n",
    "base_flag = True if base_best_acc > custom_best_acc else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score on 20 epochs: 96.68\n",
      "Accuracy Score on 50 epochs: 97.66\n",
      "Accuracy Score on 100 epochs: 98.76\n",
      "Accuracy Score on 200 epochs: 99.4\n",
      "Accuracy Score on 500 epochs: 99.73\n",
      "***** Best Hyper parameters for Classification Model *****\n",
      "\n",
      "{'activation': ReLU(), 'learning_rate': 0.001, 'optimizer': <class 'torch.optim.adam.Adam'>, 'hiden_size': 256, 'batch_size': 10, 'loss': MSELoss(), 'epochs': 500}\n"
     ]
    }
   ],
   "source": [
    "best_acc = -np.inf\n",
    "\n",
    "epochs_list = [20, 50, 100, 200, 500]\n",
    "\n",
    "if base_flag:\n",
    "    for epochs in epochs_list:\n",
    "        # Create the model: \n",
    "        model = base_Model(_params['activation'], _params['hiden_size'])\n",
    "        optimizer = optimizer_class(model.parameters(), lr=_params['learning_rate'])\n",
    "        train_accuracy = train(epochs, _params['batch_size'], _params['loss'], optimizer, model, train_set)\n",
    "        train_accuracy = float(\"{:.2f}\".format(train_accuracy))\n",
    "        \n",
    "        print(\"Accuracy Score on {} epochs: {}\".format(epochs, train_accuracy))\n",
    "        if train_accuracy > best_acc:\n",
    "            best_acc = train_accuracy\n",
    "            _params['epochs'] = epochs\n",
    "else:\n",
    "    for epochs in epochs_list:\n",
    "        # Create the model: \n",
    "        model = custmize_Model(_params['activation'], _params['hiden_size'])\n",
    "        optimizer = optimizer_class(model.parameters(), lr=_params['learning_rate'])\n",
    "        train_accuracy = train2(epochs, _params['batch_size'], _params['loss'], optimizer, model, train_set)\n",
    "        train_accuracy = float(\"{:.2f}\".format(train_accuracy))\n",
    "        \n",
    "        print(\"Accuracy Score on {} epochs: {}\".format(epochs, train_accuracy))\n",
    "        if train_accuracy > best_acc:\n",
    "            best_acc = train_accuracy\n",
    "            _params['epochs'] = epochs\n",
    "        \n",
    "print(\"***** Best Hyper parameters for Classification Model *****\\n\")\n",
    "print(_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model : 99.54 %\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy to evaluate the model\n",
    "def accuracy(dataset, model):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        dataloader = DataLoader(dataset)\n",
    "        for images, labels in dataloader:\n",
    "#             images = images.view(-1, 16*16)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)  \n",
    "            correct += (predicted == labels).sum()\n",
    "\n",
    "    print('Accuracy of the model : {:.2f} %'.format(100*correct.item()/ len(dataset)))\n",
    "\n",
    "accuracy(val_set, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model : 96.66 %\n"
     ]
    }
   ],
   "source": [
    "url = 'http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/usps.t.bz2'\n",
    "r = requests.get(url, allow_redirects=True)\n",
    "open('USPS/usps.t.bz2', 'wb').write(r.content)\n",
    "\n",
    "# Loading MNIST test set from torchvision.dataset\n",
    "test_set = torchvision.datasets.USPS(root='USPS/',\n",
    "                                         train=False,\n",
    "                                         transform=transforms.ToTensor(),\n",
    "                                         download=False)\n",
    "\n",
    "accuracy(test_set, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Single Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Prediction label: 7')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAo1UlEQVR4nO3de3BUZZ7/8U8nIZ0QkgCR3CQhEZH7TW7LRYEhkAoXB3cVcRiMuDviGC6RWYTMLqCCZnBdJopsEKsEZwsU3ZVrKQiIIMo9oMIONwkQYSBQCwlJJJD0+f3hL702CQnRPnnS4f2qOlX2OU9/n286dH883aefOCzLsgQAQB3zM90AAODORAABAIwggAAARhBAAAAjCCAAgBEEEADACAIIAGAEAQQAMIIAAgAYQQChwUlISNCTTz7pvv3555/L4XDo888/99ocDodDL7zwgtfq3a4XXnhBDofjZ903ISFBI0eO9Go/ph4HNAwEELxq2bJlcjgc7i0oKEj33XefJk2apAsXLphur1Y+/vhjXlxt9OSTT3r8W7l5O3v2rOkWYbMA0w2gYXrppZeUmJioa9euaceOHcrOztbHH3+sQ4cOqXHjxnXay4MPPqgffvhBgYGBtbrfxx9/rEWLFlUZQj/88IMCAnj6/BITJ05UUlKSxz7LsvTMM88oISFBd999t6HOUFd4BsEWKSkp6tmzpyTpn/7pnxQREaEFCxZozZo1evzxx6u8T3FxsUJCQrzei5+fn4KCgrxa09v17kR9+/ZV3759Pfbt2LFDJSUlGjdunKGuUJd4Cw514le/+pUkKTc3V9KPb780adJE3333nYYPH67Q0FD3i47L5VJWVpY6duyooKAgRUVFaeLEibp8+bJHTcuyNG/ePLVs2VKNGzfW4MGDdfjw4Upz3+ozoN27d2v48OFq1qyZQkJC1KVLF73++uvu/hYtWiRJHm8LVajqs48DBw4oJSVFYWFhatKkiYYMGaJdu3Z5jKl4i/LLL7/UtGnT1KJFC4WEhOjhhx/WxYsXa/mo/mjp0qX61a9+pcjISDmdTnXo0EHZ2dm3HP/pp5+qW7duCgoKUocOHfTRRx9VGnPlyhWlp6crLi5OTqdT9957r+bPny+Xy1VjP0eOHNGZM2d+1s+yYsUKORwO/eY3v/lZ94dv4QwIdeK7776TJEVERLj3lZWVKTk5WQMGDNBrr73mfmtu4sSJWrZsmSZMmKApU6YoNzdXb775pg4cOKAvv/xSjRo1kiTNnj1b8+bN0/DhwzV8+HDl5ORo2LBhun79eo39bNq0SSNHjlRMTIymTp2q6Oho/fWvf9X69es1depUTZw4UefOndOmTZv0n//5nzXWO3z4sB544AGFhYXp+eefV6NGjfTWW29p0KBB2rZtm/r06eMxfvLkyWrWrJnmzJmjU6dOKSsrS5MmTdLKlStv+zGtkJ2drY4dO+qhhx5SQECA1q1bp2effVYul0tpaWkeY48fP67HHntMzzzzjFJTU7V06VI9+uij2rBhg4YOHSpJKikp0cCBA3X27FlNnDhR8fHx+uqrr5SRkaG//e1vysrKqraf9u3ba+DAgbW+6OPGjRv64IMP1K9fPyUkJNTqvvBRFuBFS5cutSRZmzdvti5evGjl5eVZ77//vhUREWEFBwdb33//vWVZlpWammpJsmbOnOlx/y+++MKSZC1fvtxj/4YNGzz25+fnW4GBgdaIESMsl8vlHvfHP/7RkmSlpqa6923dutWSZG3dutWyLMsqKyuzEhMTrVatWlmXL1/2mOentdLS0qxbPUUkWXPmzHHfHj16tBUYGGh999137n3nzp2zQkNDrQcffLDS45OUlOQx13PPPWf5+/tbV65cqXK+CnPmzKnUU0lJSaVxycnJ1j333OOxr1WrVpYk67//+7/d+woKCqyYmBire/fu7n1z5861QkJCrGPHjnncf+bMmZa/v7915syZWz4OFfsGDhxY7c9RlXXr1lmSrP/4j/+o9X3hm3gLDrZISkpSixYtFBcXp7Fjx6pJkyZatWpVpQ+Wf//733vc/vDDDxUeHq6hQ4fq0qVL7q1Hjx5q0qSJtm7dKknavHmzrl+/rsmTJ3u8NZaenl5jbwcOHFBubq7S09PVtGlTj2M/5xLn8vJyffrppxo9erTuuece9/6YmBj95je/0Y4dO1RYWOhxn6efftpjrgceeEDl5eU6ffp0recPDg52/3dBQYEuXbqkgQMH6uTJkyooKPAYGxsbq4cffth9OywsTE888YQOHDig8+fPS/rxd/DAAw+oWbNmHr+DpKQklZeXa/v27dX2Y1nWz7rkfcWKFWrUqJHGjBlT6/vCN/EWHGyxaNEi3XfffQoICFBUVJTatm0rPz/P/98JCAhQy5YtPfYdP35cBQUFioyMrLJufn6+JLlfqNu0aeNxvEWLFmrWrFm1vVW8HdipU6fb/4GqcfHiRZWUlKht27aVjrVv314ul0t5eXnq2LGje398fLzHuIqeb/6c63Z8+eWXmjNnjnbu3KmSkhKPYwUFBQoPD3ffvvfeeyuF7H333SdJOnXqlKKjo3X8+HF98803atGiRZXzVfwOvKmoqEhr1qxRcnKyx9u0aNgIINiid+/e7qvgbsXpdFYKJZfLpcjISC1fvrzK+9zqRdHX+Pv7V7nfsqxa1fnuu+80ZMgQtWvXTgsWLFBcXJwCAwP18ccf689//vNtXTRwM5fLpaFDh+r555+v8nhFYHnT6tWrufrtDkQAoV5p3bq1Nm/erP79+3u8tXSzVq1aSfrxjOmnb3tdvHixxrOI1q1bS5IOHTpU6XsoP3W7b8e1aNFCjRs31tGjRysdO3LkiPz8/BQXF3dbtWpr3bp1Ki0t1dq1az3OqireqrzZiRMnZFmWx8927NgxSXJ/8N+6dWsVFRVV+9h42/Lly9WkSRM99NBDdTYnzOMzINQrY8aMUXl5uebOnVvpWFlZma5cuSLpx8+YGjVqpIULF3qcNdR0hZYk3X///UpMTFRWVpa7XoWf1qr4TtLNY27m7++vYcOGac2aNTp16pR7/4ULF7RixQoNGDBAYWFhNfb1c1ScSf2074KCAi1durTK8efOndOqVavctwsLC/WXv/xF3bp1U3R0tKQffwc7d+7Uxo0bK93/ypUrKisrq7an2l6GffHiRW3evFkPP/xwnX9JGWZxBoR6ZeDAgZo4caIyMzN18OBBDRs2TI0aNdLx48f14Ycf6vXXX9cjjzyiFi1a6J//+Z+VmZmpkSNHavjw4Tpw4IA++eQT3XXXXdXO4efnp+zsbI0aNUrdunXThAkTFBMToyNHjujw4cPuF94ePXpIkqZMmaLk5GT5+/tr7NixVdacN2+eNm3apAEDBujZZ59VQECA3nrrLZWWlurVV1/17oP0E8OGDVNgYKBGjRqliRMnqqioSG+//bYiIyP1t7/9rdL4++67T//4j/+ovXv3KioqSu+8844uXLjgEVjTp0/X2rVrNXLkSD355JPq0aOHiouL9e233+q//uu/dOrUqWof49pehr1y5UqVlZXx9tudyOQleGh4Ki4z3rt3b7XjUlNTrZCQkFseX7JkidWjRw8rODjYCg0NtTp37mw9//zz1rlz59xjysvLrRdffNGKiYmxgoODrUGDBlmHDh2yWrVqVe1l2BV27NhhDR061AoNDbVCQkKsLl26WAsXLnQfLysrsyZPnmy1aNHCcjgcHpc/q4rLj3Nycqzk5GSrSZMmVuPGja3BgwdbX3311W09Prfq8WZVXYa9du1aq0uXLlZQUJCVkJBgzZ8/33rnnXcsSVZubq57XKtWrawRI0ZYGzdutLp06WI5nU6rXbt21ocfflhpnqtXr1oZGRnWvffeawUGBlp33XWX1a9fP+u1116zrl+/Xu3joFpehv13f/d3VmRkpFVWVnbb90HD4LCsWn7qCQCAF/AZEADACAIIAGAEAQQAMIIAAgAYQQABAIwggAAARtS7L6K6XC6dO3dOoaGhP2tlYgCAWZZl6erVq4qNja203uNP1bsAOnfunG3rZgEA6k5eXl6lFe9/qt4FUGhoqKQfG7dr/Sy71LRG1i9x5MgR22rfauVpb6lY7NIOdi7df/PfLvKminXX7FDdE/6XioqKsq12TUso/RJ2/4mHinUD7VDdGUR9VVhYqLi4OPfr+a3UuwCqeNstLCyMAPqJJk2a2Fbb6XTaVlv68e/+2CUwMNC22nY+LtWt9P1L2bmgp50vtDW9WP0Sdr+WEEBVq+ljFN/9yQAAPo0AAgAYQQABAIwggAAARtgWQIsWLVJCQoKCgoLUp08f7dmzx66pAAA+yJYAWrlypaZNm6Y5c+YoJydHXbt2VXJysvLz8+2YDgDgg2wJoAULFuh3v/udJkyYoA4dOmjx4sVq3Lix3nnnHTumAwD4IK8H0PXr17V//34lJSX93yR+fkpKStLOnTsrjS8tLVVhYaHHBgBo+LweQJcuXVJ5eXmlb0xHRUXp/PnzlcZnZmYqPDzcvbEMDwDcGYxfBZeRkaGCggL3lpeXZ7olAEAd8PoaKXfddZf8/f114cIFj/0XLlyocv0rp9Np+1IwAID6x+tnQIGBgerRo4e2bNni3udyubRlyxb17dvX29MBAHyULatETps2TampqerZs6d69+6trKwsFRcXa8KECXZMBwDwQbYE0GOPPaaLFy9q9uzZOn/+vLp166YNGzbYupQ7AMC32LZO/qRJkzRp0iS7ygMAfJzxq+AAAHcmAggAYAQBBAAwggACABhh20UI9ZVlWbbVvnr1qm21v/nmG9tqf/rpp7bVlqTDhw/bVruqLzf7Qm07v3xtZ+3IyEjbardp08a22nZ/B7FXr1621bbzMffzM3sOwhkQAMAIAggAYAQBBAAwggACABhBAAEAjCCAAABGEEAAACMIIACAEQQQAMAIAggAYAQBBAAwggACABhBAAEAjCCAAABGEEAAACMIIACAEQQQAMAIAggAYAQBBAAwggACABhBAAEAjCCAAABGBJhuoK6VlZXZVjs3N9e22p999plttU+ePGlbbUlq0aKFbbVTUlJsq92uXTvbal+5csW22qdOnbKt9pkzZ2yrvXv3bttq79+/37bakvTss8/aVnvw4MG21Q4LC7Ot9u3gDAgAYAQBBAAwggACABhBAAEAjCCAAABGEEAAACMIIACAEQQQAMAIrwdQZmamevXqpdDQUEVGRmr06NE6evSot6cBAPg4rwfQtm3blJaWpl27dmnTpk26ceOGhg0bpuLiYm9PBQDwYV5fimfDhg0et5ctW6bIyEjt379fDz74YKXxpaWlKi0tdd8uLCz0dksAgHrI9s+ACgoKJEnNmzev8nhmZqbCw8PdW1xcnN0tAQDqAVsDyOVyKT09Xf3791enTp2qHJORkaGCggL3lpeXZ2dLAIB6wtbVsNPS0nTo0CHt2LHjlmOcTqecTqedbQAA6iHbAmjSpElav369tm/frpYtW9o1DQDAR3k9gCzL0uTJk7Vq1Sp9/vnnSkxM9PYUAIAGwOsBlJaWphUrVmjNmjUKDQ3V+fPnJUnh4eEKDg729nQAAB/l9YsQsrOzVVBQoEGDBikmJsa9rVy50ttTAQB8mC1vwQEAUBPWggMAGEEAAQCMIIAAAEbY+kXU+qioqMi22ocPH7at9oEDB2yrfatlkrxl5MiRttUeN26cbbVbt25tW+1r167ZVvv777+3rfbNaz160+LFi22rvWfPHttqS9KAAQNsq92jRw/baoeGhtpS93avBeAMCABgBAEEADCCAAIAGEEAAQCMIIAAAEYQQAAAIwggAIARBBAAwAgCCABgBAEEADCCAAIAGEEAAQCMIIAAAEYQQAAAIwggAIARBBAAwAgCCABgBAEEADCCAAIAGEEAAQCMIIAAAEYQQAAAIwJMN1DXLMuyrXZgYKBttdu2bWtb7YEDB9pWW5L+4R/+wbba3bt3t61248aNbav9ww8/2Fb77NmzttU+c+aMbbWLiopsqx0dHW1bbUkKDw+3rXZAQMN9meYMCABgBAEEADCCAAIAGEEAAQCMIIAAAEYQQAAAIwggAIARBBAAwAjbA+hPf/qTHA6H0tPT7Z4KAOBDbA2gvXv36q233lKXLl3snAYA4INsC6CioiKNGzdOb7/9tpo1a2bXNAAAH2VbAKWlpWnEiBFKSkqqdlxpaakKCws9NgBAw2fLKnfvv/++cnJytHfv3hrHZmZm6sUXX7SjDQBAPeb1M6C8vDxNnTpVy5cvV1BQUI3jMzIyVFBQ4N7y8vK83RIAoB7y+hnQ/v37lZ+fr/vvv9+9r7y8XNu3b9ebb76p0tJS+fv7u485nU45nU5vtwEAqOe8HkBDhgzRt99+67FvwoQJateunWbMmOERPgCAO5fXAyg0NFSdOnXy2BcSEqKIiIhK+wEAdy5WQgAAGFEnf+v1888/r4tpAAA+hDMgAIARBBAAwAgCCABgBAEEADCiTi5CqE9CQ0Ntq92vXz/basfHx9tWOzw83Lbakr29h4SE2Fa7rKzMttpnzpyxrfYnn3xiW+3PPvvMttpNmjSxrXZycrJttSWpT58+ttVu2rSpbbUdDofRupwBAQCMIIAAAEYQQAAAIwggAIARBBAAwAgCCABgBAEEADCCAAIAGEEAAQCMIIAAAEYQQAAAIwggAIARBBAAwAgCCABgBAEEADCCAAIAGEEAAQCMIIAAAEYQQAAAIwggAIARBBAAwAgCCABgRIDpBupao0aNbKt9991321Y7OjrattoOh8O22pLk7+9va327/O///q9ttbdv325b7XXr1tlW+4cffrCtdkpKim21H3vsMdtqS1KHDh1sq+10Om2rbRpnQAAAIwggAIARBBAAwAgCCABgBAEEADCCAAIAGEEAAQCMsCWAzp49q9/+9reKiIhQcHCwOnfurH379tkxFQDAR3n9i6iXL19W//79NXjwYH3yySdq0aKFjh8/rmbNmnl7KgCAD/N6AM2fP19xcXFaunSpe19iYqK3pwEA+DivvwW3du1a9ezZU48++qgiIyPVvXt3vf3227ccX1paqsLCQo8NANDweT2ATp48qezsbLVp00YbN27U73//e02ZMkXvvvtuleMzMzMVHh7u3uLi4rzdEgCgHvJ6ALlcLt1///165ZVX1L17dz399NP63e9+p8WLF1c5PiMjQwUFBe4tLy/P2y0BAOohrwdQTExMpZVh27dvrzNnzlQ53ul0KiwszGMDADR8Xg+g/v376+jRox77jh07platWnl7KgCAD/N6AD333HPatWuXXnnlFZ04cUIrVqzQkiVLlJaW5u2pAAA+zOsB1KtXL61atUrvvfeeOnXqpLlz5yorK0vjxo3z9lQAAB9my19EHTlypEaOHGlHaQBAA8FacAAAIwggAIARBBAAwAgCCABghC0XIdyp/Pzsy3M7a/uyGzdu2Fb71KlTttXesGGDbbXt7LtXr1621X7sscdsq92jRw/baktSkyZNbKvtcDhsq20ar2oAACMIIACAEQQQAMAIAggAYAQBBAAwggACABhBAAEAjCCAAABGEEAAACMIIACAEQQQAMAIAggAYAQBBAAwggACABhBAAEAjCCAAABGEEAAACMIIACAEQQQAMAIAggAYAQBBAAwggACABgRYLoB4JcoLi62rfaxY8dsq/3111/bVjswMNC22kOHDrWtdo8ePWyrHR4eblttSXI4HLbWb6g4AwIAGEEAAQCMIIAAAEYQQAAAIwggAIARBBAAwAgCCABghNcDqLy8XLNmzVJiYqKCg4PVunVrzZ07V5ZleXsqAIAP8/oXUefPn6/s7Gy9++676tixo/bt26cJEyYoPDxcU6ZM8fZ0AAAf5fUA+uqrr/TrX/9aI0aMkCQlJCTovffe0549e7w9FQDAh3n9Lbh+/fppy5Yt7mVMvv76a+3YsUMpKSlVji8tLVVhYaHHBgBo+Lx+BjRz5kwVFhaqXbt28vf3V3l5uV5++WWNGzeuyvGZmZl68cUXvd0GAKCe8/oZ0AcffKDly5drxYoVysnJ0bvvvqvXXntN7777bpXjMzIyVFBQ4N7y8vK83RIAoB7y+hnQ9OnTNXPmTI0dO1aS1LlzZ50+fVqZmZlKTU2tNN7pdMrpdHq7DQBAPef1M6CSkhL5+XmW9ff3l8vl8vZUAAAf5vUzoFGjRunll19WfHy8OnbsqAMHDmjBggV66qmnvD0VAMCHeT2AFi5cqFmzZunZZ59Vfn6+YmNjNXHiRM2ePdvbUwEAfJjXAyg0NFRZWVnKysrydmkAQAPCWnAAACMIIACAEQQQAMAIAggAYITXL0IAbmbnn+IoKCiwrfbRo0dtq3358mXbards2dK22p07d7atdkREhG21b/5uIuoHfisAACMIIACAEQQQAMAIAggAYAQBBAAwggACABhBAAEAjCCAAABGEEAAACMIIACAEQQQAMAIAggAYAQBBAAwggACABhBAAEAjCCAAABGEEAAACMIIACAEQQQAMAIAggAYAQBBAAwggACABgRYLoBNHzl5eW21b5w4YJttXNycmyrXVpaalvtdu3a2Va7ZcuWttUODAy0rTbqJ86AAABGEEAAACMIIACAEQQQAMAIAggAYAQBBAAwggACABhR6wDavn27Ro0apdjYWDkcDq1evdrjuGVZmj17tmJiYhQcHKykpCQdP37cW/0CABqIWgdQcXGxunbtqkWLFlV5/NVXX9Ubb7yhxYsXa/fu3QoJCVFycrKuXbv2i5sFADQctV4JISUlRSkpKVUesyxLWVlZ+td//Vf9+te/liT95S9/UVRUlFavXq2xY8f+sm4BAA2GVz8Dys3N1fnz55WUlOTeFx4erj59+mjnzp1V3qe0tFSFhYUeGwCg4fNqAJ0/f16SFBUV5bE/KirKfexmmZmZCg8Pd29xcXHebAkAUE8ZvwouIyNDBQUF7i0vL890SwCAOuDVAIqOjpZUeYXiCxcuuI/dzOl0KiwszGMDADR8Xg2gxMRERUdHa8uWLe59hYWF2r17t/r27evNqQAAPq7WV8EVFRXpxIkT7tu5ubk6ePCgmjdvrvj4eKWnp2vevHlq06aNEhMTNWvWLMXGxmr06NHe7BsA4ONqHUD79u3T4MGD3benTZsmSUpNTdWyZcv0/PPPq7i4WE8//bSuXLmiAQMGaMOGDQoKCvJe1wAAn1frABo0aJAsy7rlcYfDoZdeekkvvfTSL2oMANCwGb8KDgBwZyKAAABGEEAAACMIIACAEbW+CAGordLSUttq27lyxsmTJ22r7XQ6bavdvn1722pHRETYVtvPj/8fvtPwGwcAGEEAAQCMIIAAAEYQQAAAIwggAIARBBAAwAgCCABgBAEEADCCAAIAGEEAAQCMIIAAAEYQQAAAIwggAIARBBAAwAgCCABgBAEEADCCAAIAGEEAAQCMIIAAAEYQQAAAIwggAIARBBAAwIgA0w3APJfLZWv9ixcv2lZ7//79ttW2s++EhATbanfv3t222s2aNbOttsPhsK026ifOgAAARhBAAAAjCCAAgBEEEADACAIIAGAEAQQAMIIAAgAYQQABAIyodQBt375do0aNUmxsrBwOh1avXu0+duPGDc2YMUOdO3dWSEiIYmNj9cQTT+jcuXPe7BkA0ADUOoCKi4vVtWtXLVq0qNKxkpIS5eTkaNasWcrJydFHH32ko0eP6qGHHvJKswCAhqPWS/GkpKQoJSWlymPh4eHatGmTx74333xTvXv31pkzZxQfH1/pPqWlpSotLXXfLiwsrG1LAAAfZPtnQAUFBXI4HGratGmVxzMzMxUeHu7e4uLi7G4JAFAP2BpA165d04wZM/T4448rLCysyjEZGRkqKChwb3l5eXa2BACoJ2xbDfvGjRsaM2aMLMtSdnb2Lcc5nU45nU672gAA1FO2BFBF+Jw+fVqfffbZLc9+AAB3Lq8HUEX4HD9+XFu3blVERIS3pwAANAC1DqCioiKdOHHCfTs3N1cHDx5U8+bNFRMTo0ceeUQ5OTlav369ysvLdf78eUlS8+bNFRgY6L3OAQA+rdYBtG/fPg0ePNh9e9q0aZKk1NRUvfDCC1q7dq0kqVu3bh7327p1qwYNGvTzOwUANCi1DqBBgwbJsqxbHq/uGAAAFVgLDgBgBAEEADCCAAIAGEEAAQCMsG0lBPiOsrIyW+ufPn3attq7du2yrba/v79ttX96Jam3dejQwbbawcHBttXGnYczIACAEQQQAMAIAggAYAQBBAAwggACABhBAAEAjCCAAABGEEAAACMIIACAEQQQAMAIAggAYAQBBAAwggACABhBAAEAjCCAAABGEEAAACMIIACAEQQQAMAIAggAYAQBBAAwggACABhBAAEAjAgw3QDMKy0ttbX+pUuXbKtdUlJiW+17773XttoPPvigbbXvvvtu22r7+/vbVht3Hs6AAABGEEAAACMIIACAEQQQAMAIAggAYAQBBAAwggACABhR6wDavn27Ro0apdjYWDkcDq1evfqWY5955hk5HA5lZWX9ghYBAA1RrQOouLhYXbt21aJFi6odt2rVKu3atUuxsbE/uzkAQMNV65UQUlJSlJKSUu2Ys2fPavLkydq4caNGjBjxs5sDADRcXl+Kx+Vyafz48Zo+fbo6duxY4/jS0lKPpWAKCwu93RIAoB7y+kUI8+fPV0BAgKZMmXJb4zMzMxUeHu7e4uLivN0SAKAe8moA7d+/X6+//rqWLVsmh8NxW/fJyMhQQUGBe8vLy/NmSwCAesqrAfTFF18oPz9f8fHxCggIUEBAgE6fPq0//OEPSkhIqPI+TqdTYWFhHhsAoOHz6mdA48ePV1JSkse+5ORkjR8/XhMmTPDmVAAAH1frACoqKtKJEyfct3Nzc3Xw4EE1b95c8fHxioiI8BjfqFEjRUdHq23btr+8WwBAg1HrANq3b58GDx7svj1t2jRJUmpqqpYtW+a1xgAADVutA2jQoEGyLOu2x586daq2UwAA7gCsBQcAMIIAAgAYQQABAIwggAAARnh9LTj4HqfTaWv9W30J2RuGDx9uW+2mTZvaVrtz58621Q4ODratNuBNnAEBAIwggAAARhBAAAAjCCAAgBEEEADACAIIAGAEAQQAMIIAAgAYQQABAIwggAAARhBAAAAjCCAAgBEEEADACAIIAGAEAQQAMIIAAgAYQQABAIwggAAARhBAAAAjCCAAgBEEEADAiADTDdzMsixJUmFhoeFO7hzXr1+3tX5RUZFtta9du+aTta9evWpbbTufO/7+/rbVRsNR8W+w4vX8VhxWTSPq2Pfff6+4uDjTbQAAfqG8vDy1bNnylsfrXQC5XC6dO3dOoaGhcjgcNY4vLCxUXFyc8vLyFBYWVgcdegd91y1f7Vvy3d7pu27Vp74ty9LVq1cVGxsrP79bf9JT796C8/PzqzYxbyUsLMz4g/5z0Hfd8tW+Jd/tnb7rVn3pOzw8vMYxXIQAADCCAAIAGOHzAeR0OjVnzhw5nU7TrdQKfdctX+1b8t3e6btu+WLf9e4iBADAncHnz4AAAL6JAAIAGEEAAQCMIIAAAEYQQAAAI3w6gBYtWqSEhAQFBQWpT58+2rNnj+mWapSZmalevXopNDRUkZGRGj16tI4ePWq6rVr705/+JIfDofT0dNOt1Ojs2bP67W9/q4iICAUHB6tz587at2+f6baqVV5erlmzZikxMVHBwcFq3bq15s6dW+PijiZs375do0aNUmxsrBwOh1avXu1x3LIszZ49WzExMQoODlZSUpKOHz9uptmfqK7vGzduaMaMGercubNCQkIUGxurJ554QufOnTPX8P9X0+P9U88884wcDoeysrLqrL/a8NkAWrlypaZNm6Y5c+YoJydHXbt2VXJysvLz8023Vq1t27YpLS1Nu3bt0qZNm3Tjxg0NGzZMxcXFplu7bXv37tVbb72lLl26mG6lRpcvX1b//v3VqFEjffLJJ/qf//kf/fu//7uaNWtmurVqzZ8/X9nZ2XrzzTf117/+VfPnz9err76qhQsXmm6tkuLiYnXt2lWLFi2q8virr76qN954Q4sXL9bu3bsVEhKi5ORkW1cbvx3V9V1SUqKcnBzNmjVLOTk5+uijj3T06FE99NBDBjr1VNPjXWHVqlXatWuXYmNj66izn8HyUb1797bS0tLct8vLy63Y2FgrMzPTYFe1l5+fb0mytm3bZrqV23L16lWrTZs21qZNm6yBAwdaU6dONd1StWbMmGENGDDAdBu1NmLECOupp57y2Pf3f//31rhx4wx1dHskWatWrXLfdrlcVnR0tPVv//Zv7n1XrlyxnE6n9d577xnosGo3912VPXv2WJKs06dP101Tt+FWfX///ffW3XffbR06dMhq1aqV9ec//7nOe7sdPnkGdP36de3fv19JSUnufX5+fkpKStLOnTsNdlZ7BQUFkqTmzZsb7uT2pKWlacSIER6PfX22du1a9ezZU48++qgiIyPVvXt3vf3226bbqlG/fv20ZcsWHTt2TJL09ddfa8eOHUpJSTHcWe3k5ubq/PnzHv9ewsPD1adPH598rjocDjVt2tR0K9VyuVwaP368pk+fro4dO5pup1r1bjXs23Hp0iWVl5crKirKY39UVJSOHDliqKvac7lcSk9PV//+/dWpUyfT7dTo/fffV05Ojvbu3Wu6ldt28uRJZWdna9q0afrjH/+ovXv3asqUKQoMDFRqaqrp9m5p5syZKiwsVLt27eTv76/y8nK9/PLLGjdunOnWauX8+fOSVOVzteKYL7h27ZpmzJihxx9/vF6sNF2d+fPnKyAgQFOmTDHdSo18MoAairS0NB06dEg7duww3UqN8vLyNHXqVG3atElBQUGm27ltLpdLPXv21CuvvCJJ6t69uw4dOqTFixfX6wD64IMPtHz5cq1YsUIdO3bUwYMHlZ6ertjY2Hrdd0N048YNjRkzRpZlKTs723Q71dq/f79ef/115eTk3NbfUzPNJ9+Cu+uuu+Tv768LFy547L9w4YKio6MNdVU7kyZN0vr167V169af9feP6tr+/fuVn5+v+++/XwEBAQoICNC2bdv0xhtvKCAgQOXl5aZbrFJMTIw6dOjgsa99+/Y6c+aMoY5uz/Tp0zVz5kyNHTtWnTt31vjx4/Xcc88pMzPTdGu1UvF89NXnakX4nD59Wps2bar3Zz9ffPGF8vPzFR8f736enj59Wn/4wx+UkJBgur1KfDKAAgMD1aNHD23ZssW9z+VyacuWLerbt6/BzmpmWZYmTZqkVatW6bPPPlNiYqLplm7LkCFD9O233+rgwYPurWfPnho3bpwOHjwof39/0y1WqX///pUucz927JhatWplqKPbU1JSUukvSfr7+8vlchnq6OdJTExUdHS0x3O1sLBQu3fvrvfP1YrwOX78uDZv3qyIiAjTLdVo/Pjx+uabbzyep7GxsZo+fbo2btxour1KfPYtuGnTpik1NVU9e/ZU7969lZWVpeLiYk2YMMF0a9VKS0vTihUrtGbNGoWGhrrfBw8PD1dwcLDh7m4tNDS00udUISEhioiIqNefXz333HPq16+fXnnlFY0ZM0Z79uzRkiVLtGTJEtOtVWvUqFF6+eWXFR8fr44dO+rAgQNasGCBnnrqKdOtVVJUVKQTJ064b+fm5urgwYNq3ry54uPjlZ6ernnz5qlNmzZKTEzUrFmzFBsbq9GjR5trWtX3HRMTo0ceeUQ5OTlav369ysvL3c/V5s2bKzAw0FTbNT7eNwdlo0aNFB0drbZt29Z1qzUzfRneL7Fw4UIrPj7eCgwMtHr37m3t2rXLdEs1klTltnTpUtOt1ZovXIZtWZa1bt06q1OnTpbT6bTatWtnLVmyxHRLNSosLLSmTp1qxcfHW0FBQdY999xj/cu//ItVWlpqurVKtm7dWuW/6dTUVMuyfrwUe9asWVZUVJTldDqtIUOGWEePHjXbtFV937m5ubd8rm7durXe9l2V+nwZNn8PCABghE9+BgQA8H0EEADACAIIAGAEAQQAMIIAAgAYQQABAIwggAAARhBAAAAjCCAAgBEEEADACAIIAGDE/wM5/CTbaUYb9gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_index = 66\n",
    "\n",
    "(image, label) = val_set[val_index]\n",
    "output = model(image)\n",
    "_, prediction = torch.max(output.data, 1)\n",
    "\n",
    "plt.imshow(image.view(16, 16), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "plt.title(\"Prediction label: %d\" % prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "ba5ba4c049791c3047b698a7cd400296017c86ac9307a8bdfda620d9863f10c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
