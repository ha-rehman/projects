{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b58c7b62-4293-4aae-a6a8-268c8bd44243",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from transformers import BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2aa971b-75ad-47e3-9b67-61bece0d0877",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c149b472-27cc-41e1-b6e0-0291af420878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b44395fa-6362-4ae9-bf6f-24990da678a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce867577-e7f2-4996-a00b-549f35d29190",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0f63dbd-fd96-4c53-b780-93443fefef0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "951889bc-663e-4ac9-91e3-0c29e06b5d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b505655a-d603-435d-b659-381b5f7cebcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490027de-e416-405f-b964-c42c0f15ce64",
   "metadata": {},
   "source": [
    "## Load and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25ddddb0-1bf1-45b6-94bf-9b63daedffae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          description  labels\n",
      "0                                   Das weiße Tshirt.  Tshirt\n",
      "1                               Ein Kleid mit Blumen.   Kleid\n",
      "2                               Eine lange Jeanshose.    Hose\n",
      "3                                  Tshirt mit Muster.  Tshirt\n",
      "4                         Hose mit Print und Taschen.    Hose\n",
      "5                         Ausfallendes Kleid in lila.   Kleid\n",
      "6                 Lang geschnittenes Shirt aus Wolle.  Tshirt\n",
      "7                              Edles Kleid aus Satin.   Kleid\n",
      "8                            Culotte mit weitem Bein.    Hose\n",
      "9   Kurze Ärmel und weite Passform machen das Shir...  Tshirt\n",
      "10  Dicker Stoff macht die Hose zum idealen Winter...    Hose\n",
      "11                          Kleid mit dünnen Trägern.   Kleid\n",
      "12                                     Top mit Print.  Tshirt\n",
      "13                          Schlaghose aus den 70ern.    Hose\n",
      "14               Blaue Jeans mit Blumenapplikationen.    Hose\n",
      "15                Gestricktes Kleid mit V-Ausschnitt.   Kleid\n",
      "16                   Langärmliges Shirt mit Streifen.  Tshirt\n",
      "17                          Kurze Shorts mit Taschen.    Hose\n",
      "18                                 Trägertop in rosa.  Tshirt\n",
      "19                   Hemdblusenkleid aus Strickstoff.   Kleid\n",
      "20                 Kurze Jeans mit Strassapllikation.    Hose\n",
      "21         Blaues Basic-Shirt mit Rundhalsausschnitt.  Tshirt\n"
     ]
    }
   ],
   "source": [
    "data = {'description': ['Das weiße Tshirt.', 'Ein Kleid mit Blumen.', 'Eine lange Jeanshose.',\n",
    "                 'Tshirt mit Muster.', 'Hose mit Print und Taschen.', 'Ausfallendes Kleid in lila.',\n",
    "                 'Lang geschnittenes Shirt aus Wolle.', 'Edles Kleid aus Satin.', 'Culotte mit weitem Bein.',\n",
    "                 'Kurze Ärmel und weite Passform machen das Shirt zum Allrounder.',\n",
    "                 'Dicker Stoff macht die Hose zum idealen Winterbegleiter.', 'Kleid mit dünnen Trägern.',\n",
    "                 'Top mit Print.', 'Schlaghose aus den 70ern.', 'Blaue Jeans mit Blumenapplikationen.',\n",
    "                 'Gestricktes Kleid mit V-Ausschnitt.', 'Langärmliges Shirt mit Streifen.',\n",
    "                 'Kurze Shorts mit Taschen.', 'Trägertop in rosa.', 'Hemdblusenkleid aus Strickstoff.', 'Kurze Jeans mit Strassapllikation.', 'Blaues Basic-Shirt mit Rundhalsausschnitt.'],\n",
    "        'labels': ['Tshirt', 'Kleid', 'Hose', 'Tshirt', 'Hose', 'Kleid', 'Tshirt', 'Kleid', 'Hose', 'Tshirt',\n",
    "                  'Hose', 'Kleid', 'Tshirt', 'Hose', 'Hose', 'Kleid', 'Tshirt', 'Hose', 'Tshirt', 'Kleid', 'Hose', 'Tshirt']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6114892f-65fd-405e-9217-faa2c9d36352",
   "metadata": {},
   "source": [
    "### Encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b78474b-7aa5-4c24-a681-4c5f4970f370",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Tshirt': 0, 'Kleid': 1, 'Hose': 2}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_labels = df.labels.unique()\n",
    "\n",
    "label_dict = {}\n",
    "for index, possible_label in enumerate(possible_labels):\n",
    "    label_dict[possible_label] = index\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a1cfe8d-1c9b-46a6-887c-b99b4b9764a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['labels'] = df.labels.replace(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c315921-3630-4539-a617-d1162a2fd778",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Das weiße Tshirt.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ein Kleid mit Blumen.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eine lange Jeanshose.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tshirt mit Muster.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hose mit Print und Taschen.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ausfallendes Kleid in lila.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lang geschnittenes Shirt aus Wolle.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Edles Kleid aus Satin.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Culotte mit weitem Bein.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Kurze Ärmel und weite Passform machen das Shir...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Dicker Stoff macht die Hose zum idealen Winter...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Kleid mit dünnen Trägern.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Top mit Print.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Schlaghose aus den 70ern.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Blaue Jeans mit Blumenapplikationen.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Gestricktes Kleid mit V-Ausschnitt.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Langärmliges Shirt mit Streifen.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Kurze Shorts mit Taschen.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Trägertop in rosa.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Hemdblusenkleid aus Strickstoff.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Kurze Jeans mit Strassapllikation.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Blaues Basic-Shirt mit Rundhalsausschnitt.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          description  labels\n",
       "0                                   Das weiße Tshirt.       0\n",
       "1                               Ein Kleid mit Blumen.       1\n",
       "2                               Eine lange Jeanshose.       2\n",
       "3                                  Tshirt mit Muster.       0\n",
       "4                         Hose mit Print und Taschen.       2\n",
       "5                         Ausfallendes Kleid in lila.       1\n",
       "6                 Lang geschnittenes Shirt aus Wolle.       0\n",
       "7                              Edles Kleid aus Satin.       1\n",
       "8                            Culotte mit weitem Bein.       2\n",
       "9   Kurze Ärmel und weite Passform machen das Shir...       0\n",
       "10  Dicker Stoff macht die Hose zum idealen Winter...       2\n",
       "11                          Kleid mit dünnen Trägern.       1\n",
       "12                                     Top mit Print.       0\n",
       "13                          Schlaghose aus den 70ern.       2\n",
       "14               Blaue Jeans mit Blumenapplikationen.       2\n",
       "15                Gestricktes Kleid mit V-Ausschnitt.       1\n",
       "16                   Langärmliges Shirt mit Streifen.       0\n",
       "17                          Kurze Shorts mit Taschen.       2\n",
       "18                                 Trägertop in rosa.       0\n",
       "19                   Hemdblusenkleid aus Strickstoff.       1\n",
       "20                 Kurze Jeans mit Strassapllikation.       2\n",
       "21         Blaues Basic-Shirt mit Rundhalsausschnitt.       0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49cd728-1a14-44b2-8dac-67ecb86b6a30",
   "metadata": {},
   "source": [
    "### Train and Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e0b25df-35e8-4c77-91da-3d7dec5fc0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.5\n",
    "validation_ratio = 0.2\n",
    "test_ratio = 0.3\n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "X_train, X_val, y_train, y_val = train_test_split(df.description.values, df.labels.values, test_size=1 - train_ratio, random_state=42, stratify=df.labels.values)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=test_ratio/(test_ratio + validation_ratio), random_state=42, stratify=y_val) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81418932-832a-4d09-a1f6-5ee0f6f335c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Eine lange Jeanshose.',\n",
       " 'Das weiße Tshirt.',\n",
       " 'Blaue Jeans mit Blumenapplikationen.',\n",
       " 'Kleid mit dünnen Trägern.',\n",
       " 'Tshirt mit Muster.',\n",
       " 'Hemdblusenkleid aus Strickstoff.',\n",
       " 'Blaues Basic-Shirt mit Rundhalsausschnitt.',\n",
       " 'Hose mit Print und Taschen.',\n",
       " 'Langärmliges Shirt mit Streifen.',\n",
       " 'Ein Kleid mit Blumen.',\n",
       " 'Kurze Shorts mit Taschen.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert array to list\n",
    "np.ndarray.tolist(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ff473e3-8cd9-4c54-82f9-e0a67726c545",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Culotte mit weitem Bein.',\n",
       " 'Trägertop in rosa.',\n",
       " 'Schlaghose aus den 70ern.',\n",
       " 'Edles Kleid aus Satin.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert array to list\n",
    "np.ndarray.tolist(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce7e86ad-4719-411f-acd6-e53f2da1ed5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kurze Ärmel und weite Passform machen das Shirt zum Allrounder.',\n",
       " 'Top mit Print.',\n",
       " 'Dicker Stoff macht die Hose zum idealen Winterbegleiter.',\n",
       " 'Gestricktes Kleid mit V-Ausschnitt.',\n",
       " 'Ausfallendes Kleid in lila.',\n",
       " 'Kurze Jeans mit Strassapllikation.',\n",
       " 'Lang geschnittenes Shirt aus Wolle.']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert array to list\n",
    "np.ndarray.tolist(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5688bf06-7a5b-4da7-84a1-109b534e6526",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 0, 2, 1, 0, 1, 0, 2, 0, 1, 2]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert array to list\n",
    "np.ndarray.tolist(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8aff926d-13ff-4e00-b880-6611c933755c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 0, 2, 1]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert array to list\n",
    "np.ndarray.tolist(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bcbbb6be-df8e-4a5e-aecb-806784eb7c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 2, 1, 1, 2, 0]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert array to list\n",
    "np.ndarray.tolist(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a4f5e1-f7bb-440c-af86-950ed8574a16",
   "metadata": {},
   "source": [
    "### Tokenization and data encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d1e8ce9-fea9-4098-8e83-c945d496c848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a25d624065a47cc98544579e2407b8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/83.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cf36aa4a25348c2b9fc17b3bf3c162d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/362 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "680e61700420490aa2a25752c8b0d310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/240k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='deepset/gbert-base', vocab_size=31102, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initilalize the tokenizer\n",
    "checkpoint = \"deepset/gbert-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f42bc92f-631e-41cd-b585-4973ebb3c373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function for encoding\n",
    "def encode(docs):\n",
    "    '''\n",
    "    This function takes list of texts and returns input_ids and attention_mask of texts\n",
    "    '''\n",
    "    encoded_dict = tokenizer.batch_encode_plus(docs, add_special_tokens=True, max_length=20, padding='max_length',\n",
    "                            return_attention_mask=True, truncation=True, return_tensors='pt')\n",
    "    input_ids = encoded_dict['input_ids']\n",
    "    attention_masks = encoded_dict['attention_mask']\n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "108b3667-af1a-4e23-96eb-8185f20c7ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usage of the 'encode' function\n",
    "train_input_ids, train_att_masks = encode(X_train.tolist())\n",
    "valid_input_ids, valid_att_masks = encode(X_val.tolist())\n",
    "test_input_ids, test_att_masks = encode(X_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "821f6570-4108-4b2a-b20d-6ef79b1c6fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tensors of labels\n",
    "labels_train = torch.tensor(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ce68a41d-d69f-4a6a-97d2-cfb4e1b42d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_val = torch.tensor(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9dd52038-89a9-4af6-abe4-58217e65467e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test = torch.tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "59084abc-d7bb-4ca8-abb9-9d6bbeda1cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the dataset together\n",
    "dataset_train = TensorDataset(train_input_ids, train_att_masks, labels_train)\n",
    "dataset_val = TensorDataset(valid_input_ids, valid_att_masks, labels_val)\n",
    "dataset_test = TensorDataset(test_input_ids, test_att_masks, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d6eac6-265b-4a7c-b45b-6a2769810ee9",
   "metadata": {},
   "source": [
    "#### Get the tokens from the token ids to use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "471d41bd-49a6-4925-85f5-9ad8a72806c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the tokens for each sample in the training set\n",
    "train_tokens = []\n",
    "for input_id in train_input_ids:\n",
    "    train_tokens.append(tokenizer.convert_ids_to_tokens(input_id.tolist()))\n",
    "\n",
    "# Get the tokens for each sample in the validation set\n",
    "valid_tokens = []\n",
    "for input_id in valid_input_ids:\n",
    "    valid_tokens.append(tokenizer.convert_ids_to_tokens(input_id.tolist()))\n",
    "    \n",
    "# Get the tokens for each sample in the test set\n",
    "test_tokens = []\n",
    "for input_id in test_input_ids:\n",
    "    test_tokens.append(tokenizer.convert_ids_to_tokens(input_id.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851ae07e-318a-4333-bf9c-41181e7aec74",
   "metadata": {},
   "source": [
    "## Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b453e945-64b7-4a0e-abcf-445b34b8a46f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fcca9741-282a-48d5-a79c-a4bbc463985d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc986ed8877a47219e7c9ee2af9d0353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/442M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint,\n",
    "                                                      num_labels=len(label_dict),\n",
    "                                                      output_attentions=True,\n",
    "                                                      output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfa6f29-6f60-4b3d-9df3-636250a25c78",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3c9be956-0fb7-4e56-928b-7b0d99213818",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 3\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, \n",
    "                              sampler=RandomSampler(dataset_train), \n",
    "                              batch_size=batch_size)\n",
    "\n",
    "dataloader_validation = DataLoader(dataset_val, \n",
    "                                   sampler=SequentialSampler(dataset_val), #Doku lesen ob bei seq sampler die reihenfolge gleich\n",
    "                                   batch_size=batch_size)\n",
    "\n",
    "dataloader_test = DataLoader(dataset_test, \n",
    "                                   sampler=SequentialSampler(dataset_test), #Doku lesen ob bei seq sampler die reihenfolge gleich\n",
    "                                   batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f01661-2bee-4446-8324-780305aced40",
   "metadata": {},
   "source": [
    "## Optimizers and schedulers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e4d1adc9-fb91-425d-9399-f02a9fc7c00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters())#,\n",
    "                  #lr=5e-5, #1e-5\n",
    "                  #eps=1e-8)\n",
    "                  \n",
    "epochs = 5\n",
    "\n",
    "#scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            #num_warmup_steps=0,\n",
    "                                           # num_training_steps=len(dataloader_train)*epochs)\n",
    "\n",
    "#This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6559c16-cef1-45f8-8ebc-996b1db6e5dd",
   "metadata": {},
   "source": [
    "## Define Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "518ab630-8800-431f-8617-81cd801e1620",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
    "\n",
    "def accuracy_per_class(preds, labels):\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "    \n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5d3029a0-77d3-42e7-b676-df0e16fac96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def overallaccuracy(labels, preds):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return accuracy_score(labels_flat, preds_flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "63773abf-1910-41d4-b94a-06b645e377ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCC\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "def mcc_score_func(labels, preds):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return matthews_corrcoef(labels_flat, preds_flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "852ac442-5446-4e98-aabc-53f577b65a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def accuracy_per_class_df(preds, labels, label_dict):\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "    \n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    \n",
    "    acc_df = pd.DataFrame(columns=[\"class\", \"correct_preds\", \"total_preds\"])\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        class_name = label_dict_inverse[label]\n",
    "        correct_preds = len(y_preds[y_preds==label])\n",
    "        total_preds = len(y_true)\n",
    "        acc_df = acc_df.append({\"class\": class_name, \"correct_preds\": correct_preds, \"total_preds\": total_preds}, ignore_index=True)\n",
    "    \n",
    "    return acc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9a4a21-609f-453c-8c7b-928628065689",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1f8086b4-150a-40f9-9c6c-5add73ca945e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c7996bcf-4194-449c-93e2-3eedb0ad7b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5b2cbc6d-d19a-42d2-8677-7005e91cbd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "misclassified_examples_dict = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4a64538d-7107-4ea4-a8ff-c251a7074d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(misclassified_examples_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "05ff1c79-2b14-482a-88f1-91c73aa9513b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a63a805f7314e50a226be10ee7f1ccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training loss: 2.0209629237651825\n",
      "Validation loss: 1.0202228128910065\n",
      "F1 Score (Weighted): 0.1\n",
      "Overall Accuracy: 0.25\n",
      "MCC: 0.0\n",
      "Class: Tshirt\n",
      "Accuracy: 0/1\n",
      "\n",
      "Class: Kleid\n",
      "Accuracy: 1/1\n",
      "\n",
      "Class: Hose\n",
      "Accuracy: 0/2\n",
      "\n",
      "Accuracy per class: None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2\n",
      "Training loss: 2.479090854525566\n",
      "Validation loss: 1.3147750794887543\n",
      "F1 Score (Weighted): 0.3333333333333333\n",
      "Overall Accuracy: 0.5\n",
      "MCC: 0.0\n",
      "Class: Tshirt\n",
      "Accuracy: 0/1\n",
      "\n",
      "Class: Kleid\n",
      "Accuracy: 0/1\n",
      "\n",
      "Class: Hose\n",
      "Accuracy: 2/2\n",
      "\n",
      "Accuracy per class: None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3\n",
      "Training loss: 1.695324033498764\n",
      "Validation loss: 1.726254403591156\n",
      "F1 Score (Weighted): 0.1\n",
      "Overall Accuracy: 0.25\n",
      "MCC: 0.0\n",
      "Class: Tshirt\n",
      "Accuracy: 1/1\n",
      "\n",
      "Class: Kleid\n",
      "Accuracy: 0/1\n",
      "\n",
      "Class: Hose\n",
      "Accuracy: 0/2\n",
      "\n",
      "Accuracy per class: None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4\n",
      "Training loss: 1.1695346981287003\n",
      "Validation loss: 1.174277514219284\n",
      "F1 Score (Weighted): 0.3333333333333333\n",
      "Overall Accuracy: 0.5\n",
      "MCC: 0.0\n",
      "Class: Tshirt\n",
      "Accuracy: 0/1\n",
      "\n",
      "Class: Kleid\n",
      "Accuracy: 0/1\n",
      "\n",
      "Class: Hose\n",
      "Accuracy: 2/2\n",
      "\n",
      "Accuracy per class: None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5\n",
      "Training loss: 1.053799569606781\n",
      "Validation loss: 1.0717858672142029\n",
      "F1 Score (Weighted): 0.3333333333333333\n",
      "Overall Accuracy: 0.5\n",
      "MCC: 0.0\n",
      "Class: Tshirt\n",
      "Accuracy: 0/1\n",
      "\n",
      "Class: Kleid\n",
      "Accuracy: 0/1\n",
      "\n",
      "Class: Hose\n",
      "Accuracy: 2/2\n",
      "\n",
      "Accuracy per class: None\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "seed_val = 17\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "def evaluate(dataloader_val): \n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    global attention_weights\n",
    "    attention_weights = []\n",
    "    \n",
    "    for batch in dataloader_val:\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0], \n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "        #ATTENTION WEIGHTS    \n",
    "        attention_weights_final_layer = outputs.attentions[11].cpu().detach().numpy()\n",
    "        for sampleindex in range(len(inputs['input_ids'])):\n",
    "            sample_attention_weights = []\n",
    "            for keyindex in range(len(attention_weights_final_layer[sampleindex, 0, 0])):\n",
    "                x = attention_weights_final_layer[sampleindex, :, 0, keyindex].mean() \n",
    "                sample_attention_weights.append(x)\n",
    "            attention_weights.append(sample_attention_weights)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "\n",
    " \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "    \n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "    misclassified = np.where(preds != true_vals)[0]\n",
    "    \n",
    "\n",
    "    \n",
    "    texts = X_val.tolist()\n",
    "    \n",
    "    global misclassified_examples\n",
    "    misclassified_examples = []\n",
    "    \n",
    "    global misclassified_examples_dict\n",
    "\n",
    "    misclassified_examples_dict = defaultdict(list)\n",
    "    val_indices = np.arange(len(X_val))\n",
    "\n",
    "    for idx in misclassified: \n",
    "        text = texts[idx]\n",
    "        true_label = true_vals[idx]\n",
    "        pred_label = preds[idx]\n",
    "        val_index = val_indices[idx]\n",
    "        misclassified_examples.append({\n",
    "            'text': text,\n",
    "            'true_label': true_label,\n",
    "            'pred_label': pred_label,\n",
    "            'val_index': val_index\n",
    "        })\n",
    "\n",
    "            \n",
    "    return loss_val_avg, predictions, true_vals\n",
    "\n",
    "step_count = 0\n",
    "train_loss_per_step = [] \n",
    "val_loss_per_step = [] \n",
    "val_acc_per_step = []\n",
    "\n",
    "train_losses = [] \n",
    "val_losses = []\n",
    "overall_accuracy = []\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    loss_train_total = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "    for batch in progress_bar:\n",
    "        \n",
    "#\n",
    "\n",
    "        model.zero_grad()\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }       \n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        #scheduler.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "        \n",
    "        step_count += 1  \n",
    "        \n",
    "        if step_count % 3 == 0:  \n",
    "            loss_train_avg_per_step = loss_train_total/len(dataloader_train) \n",
    "            train_loss_per_step.append((step_count,loss_train_avg_per_step)) \n",
    "            \n",
    "    \n",
    "    loss_train_avg = loss_train_total/len(dataloader_train) \n",
    "    train_losses.append(loss_train_avg) \n",
    "\n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "    loss_train_avg = loss_train_total/len(dataloader_train)            \n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_validation) \n",
    "    \n",
    "    if step_count % 3 == 0:  \n",
    "            loss_val_per_step = val_loss \n",
    "            val_loss_per_step.append((step_count,loss_val_per_step)) \n",
    "            \n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (Weighted): {val_f1}')\n",
    "    \n",
    "    val_overallaccuracy = overallaccuracy(true_vals, predictions)\n",
    "    tqdm.write(f'Overall Accuracy: {val_overallaccuracy}')\n",
    "    \n",
    "    if step_count % 3 == 0:  \n",
    "            acc_per_step = val_loss \n",
    "            val_acc_per_step.append((step_count,val_overallaccuracy))\n",
    "    \n",
    "    val_mcc = mcc_score_func(true_vals, predictions)\n",
    "    tqdm.write(f'MCC: {val_mcc}')\n",
    "    \n",
    "    val_acc = accuracy_per_class(predictions, true_vals)\n",
    "    tqdm.write(f'Accuracy per class: {val_acc}')\n",
    "    \n",
    "    val_losses.append(val_loss) \n",
    "    overall_accuracy.append(val_overallaccuracy) \n",
    "    \n",
    "    \n",
    "    global val_acc_df\n",
    "    val_acc_df = accuracy_per_class_df(predictions, true_vals, label_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbb5826-0aed-471d-8b59-412b52978d97",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Attention weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "503460a7-6563-4aca-9479-8a9d559499e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>true_label</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>tokens</th>\n",
       "      <th>attention_weights</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trägertop in rosa.</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[[CLS], Träger, ##top, in, ro, ##sa, ., [SEP], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD]]</td>\n",
       "      <td>[0.124999814, 0.12500016, 0.12499993, 0.1250001, 0.12500006, 0.12499984, 0.12500003, 0.12500009, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Edles Kleid aus Satin.</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[[CLS], Ed, ##les, Kleid, aus, Sat, ##in, ., [SEP], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD]]</td>\n",
       "      <td>[0.111110836, 0.11111111, 0.11111096, 0.11111129, 0.111111276, 0.111110985, 0.1111111, 0.11111119, 0.111111216, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             text  true_label  pred_label  \\\n",
       "val_index                                                   \n",
       "1              Trägertop in rosa.           0           2   \n",
       "3          Edles Kleid aus Satin.           1           2   \n",
       "\n",
       "                                                                                                                                       tokens  \\\n",
       "val_index                                                                                                                                       \n",
       "1          [[CLS], Träger, ##top, in, ro, ##sa, ., [SEP], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD]]   \n",
       "3            [[CLS], Ed, ##les, Kleid, aus, Sat, ##in, ., [SEP], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD]]   \n",
       "\n",
       "                                                                                                                                                                attention_weights  \n",
       "val_index                                                                                                                                                                          \n",
       "1                    [0.124999814, 0.12500016, 0.12499993, 0.1250001, 0.12500006, 0.12499984, 0.12500003, 0.12500009, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "3          [0.111110836, 0.11111111, 0.11111096, 0.11111129, 0.111111276, 0.111110985, 0.1111111, 0.11111119, 0.111111216, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform list to df\n",
    "misclassifications = pd.DataFrame(misclassified_examples)\n",
    "\n",
    "# set the maximum column width to a large number to display full text\n",
    "pd.set_option('display.max_colwidth', None) #alternativ statt none eine Zahl um die Anzahl an Zeichen die geprintet werden sollen festzulegen\n",
    "\n",
    "# add a new column to the DataFrame with the token information\n",
    "tokens_series = pd.Series(valid_tokens, name='tokens')\n",
    "\n",
    "# only join tokens to the rows that have a matching val_index in df\n",
    "misclassifications = pd.merge(misclassifications, tokens_series, left_on='val_index', right_index=True, how='left')\n",
    "\n",
    "# you can set the index column to be the val_index column\n",
    "misclassifications.set_index('val_index', inplace=True)\n",
    "\n",
    "# add a new column to the DataFrame with the attention weights\n",
    "weights_series = pd.Series(attention_weights, name='attention_weights')\n",
    "\n",
    "# only join weights to the rows that have a matching index in df\n",
    "misclassifications = pd.merge(misclassifications, weights_series, left_index=True, right_index=True, how='left')\n",
    "\n",
    "# view the resulting dataframe\n",
    "misclassifications"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cu110.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m103"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
