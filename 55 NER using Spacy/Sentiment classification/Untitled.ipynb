{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0f0402b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 12.8/12.8 MB 1.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.6.0,>=3.5.0 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from en-core-web-sm==3.5.0) (3.5.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.64.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.21.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.28.1)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (59.5.0)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.9)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.7)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (22.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.13)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.1)\n",
      "\u001b[38;5;3m[!] As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use\n",
      "the full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 12:13:08.620867: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2023-04-05 12:13:08.620914: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-04-05 12:13:11.852416: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'nvcuda.dll'; dlerror: nvcuda.dll not found\n",
      "2023-04-05 12:13:11.852450: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-04-05 12:13:11.855399: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: DESKTOP-38ONH9K\n",
      "2023-04-05 12:13:11.855469: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: DESKTOP-38ONH9K\n",
      "C:\\Users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages\\numpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll\n",
      "C:\\Users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "011e7afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy[en] in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (3.5.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy[en]) (3.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy[en]) (2.4.6)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy[en]) (0.7.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy[en]) (2.0.7)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy[en]) (6.3.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy[en]) (3.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy[en]) (59.5.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy[en]) (1.0.9)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy[en]) (1.0.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy[en]) (3.0.8)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy[en]) (0.10.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy[en]) (3.0.12)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy[en]) (2.28.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy[en]) (1.1.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy[en]) (2.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy[en]) (8.1.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy[en]) (22.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy[en]) (1.10.7)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy[en]) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy[en]) (1.21.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy[en]) (4.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy[en]) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy[en]) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy[en]) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy[en]) (2022.12.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy[en]) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy[en]) (0.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy[en]) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy[en]) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from jinja2->spacy[en]) (2.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: spacy 3.5.1 does not provide the extra 'en'\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy[en]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "914e1164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.5.0\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "Requirement already satisfied: spacy<3.6.0,>=3.5.0 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from en-core-web-sm==3.5.0) (3.5.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.64.1)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.9)\n",
      "Requirement already satisfied: setuptools in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (59.5.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.28.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (22.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.21.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.7)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.1)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.1)\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 12:13:56.088971: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2023-04-05 12:13:56.089019: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-04-05 12:13:59.238088: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'nvcuda.dll'; dlerror: nvcuda.dll not found\n",
      "2023-04-05 12:13:59.238116: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-04-05 12:13:59.240976: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: DESKTOP-38ONH9K\n",
      "2023-04-05 12:13:59.241054: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: DESKTOP-38ONH9K\n",
      "C:\\Users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages\\numpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll\n",
      "C:\\Users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "337b0203",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m(\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtner/bionlp2004\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m      3\u001b[0m     cache_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data_cache\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m )\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe dataset is a dictionary with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(dataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m splits: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\n",
    "    \"tner/bionlp2004\", \n",
    "    cache_dir='./data_cache'\n",
    ")\n",
    "\n",
    "print(f'The dataset is a dictionary with {len(dataset)} splits: \\n\\n{dataset}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63013504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul\\anaconda3\\envs\\enr\\lib\\site-packages\\spacy\\data\\en\\en_lookups.json\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from pathlib import Path\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "language = nlp.meta[\"lang\"]\n",
    "\n",
    "data_path = Path(spacy.__file__).parent / \"data\"\n",
    "lookups_path = data_path / language / f\"{language}_lookups.json\"\n",
    "\n",
    "print(lookups_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a78ae82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul\\anaconda3\\envs\\enr\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Elon Musk is the CEO of SpaceX and Tesla.\" with entities \"[(0, 8, 'PERSON'), (23, 28, 'ORG'), (33, 38, 'ORG'...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities (with BILUO tag '-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\abdul\\anaconda3\\envs\\enr\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Steve Jobs was the CEO of Apple.\" with entities \"[(0, 10, 'PERSON'), (24, 29, 'ORG')]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities (with BILUO tag '-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\abdul\\anaconda3\\envs\\enr\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Mark Zuckerberg is the CEO of Facebook.\" with entities \"[(0, 14, 'PERSON'), (23, 31, 'ORG')]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities (with BILUO tag '-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\abdul\\anaconda3\\envs\\enr\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Satya Nadella is the CEO of Microsoft.\" with entities \"[(0, 12, 'PERSON'), (23, 33, 'ORG')]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities (with BILUO tag '-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\abdul\\anaconda3\\envs\\enr\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Barack Obama was the 44th President of the United ...\" with entities \"[(0, 12, 'PERSON'), (34, 50, 'GPE')]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities (with BILUO tag '-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 8.493480837100172}\n",
      "Losses {'ner': 8.25667298793175}\n",
      "Losses {'ner': 4.598021725868421}\n",
      "Losses {'ner': 2.9665479305567235}\n",
      "Losses {'ner': 5.917030490791238}\n",
      "Losses {'ner': 5.640648760218085}\n",
      "Losses {'ner': 6.773055590106651}\n",
      "Losses {'ner': 1.9615919114081084}\n",
      "Losses {'ner': 4.219486742215118}\n",
      "Losses {'ner': 5.376346936847625}\n",
      "Losses {'ner': 0.11255781556617678}\n",
      "Losses {'ner': 1.3494327464794034}\n",
      "Losses {'ner': 0.04187934193344675}\n",
      "Losses {'ner': 2.7366248860900133}\n",
      "Losses {'ner': 0.19335129249938837}\n",
      "Losses {'ner': 2.5105282781453635}\n",
      "Losses {'ner': 0.09814465328435618}\n",
      "Losses {'ner': 0.004293845070271283}\n",
      "Losses {'ner': 3.1361011982388334}\n",
      "Losses {'ner': 1.2624570904219983}\n",
      "Losses {'ner': 1.9344839841398287}\n",
      "Losses {'ner': 1.1169383715815366}\n",
      "Losses {'ner': 1.9873940701885193}\n",
      "Losses {'ner': 0.951446766934929}\n",
      "Losses {'ner': 0.0017042636317348943}\n",
      "Losses {'ner': 0.08521360092290241}\n",
      "Losses {'ner': 3.390597311453636}\n",
      "Losses {'ner': 0.41348719631765446}\n",
      "Losses {'ner': 0.04453541997828422}\n",
      "Losses {'ner': 1.8000877963498558}\n",
      "Losses {'ner': 0.03334192885109472}\n",
      "Losses {'ner': 4.231041444582883}\n",
      "Losses {'ner': 0.8231030030168172}\n",
      "Losses {'ner': 0.00024131392943430404}\n",
      "Losses {'ner': 0.5365137626596832}\n",
      "Losses {'ner': 1.621060206874077}\n",
      "Losses {'ner': 1.7039081922127273}\n",
      "Losses {'ner': 0.0008660199864660445}\n",
      "Losses {'ner': 0.00035717706478002615}\n",
      "Losses {'ner': 0.07379120074643457}\n",
      "Losses {'ner': 0.00804794828887292}\n",
      "Losses {'ner': 0.0004147560037264472}\n",
      "Losses {'ner': 0.0011488280142254814}\n",
      "Losses {'ner': 0.005239043761224699}\n",
      "Losses {'ner': 2.1114762465925617e-05}\n",
      "Losses {'ner': 0.0005917070727224893}\n",
      "Losses {'ner': 1.2391397090847458e-07}\n",
      "Losses {'ner': 1.961532993826725}\n",
      "Losses {'ner': 0.030137615368789818}\n",
      "Losses {'ner': 0.032429414327318565}\n",
      "Losses {'ner': 0.002499875306244966}\n",
      "Losses {'ner': 4.069324402562488}\n",
      "Losses {'ner': 5.421889611025718e-05}\n",
      "Losses {'ner': 2.315231657524241e-05}\n",
      "Losses {'ner': 0.019056572777658157}\n",
      "Losses {'ner': 3.9966350981609704}\n",
      "Losses {'ner': 0.0004111836712427325}\n",
      "Losses {'ner': 4.201829935402574e-06}\n",
      "Losses {'ner': 0.011353614390681423}\n",
      "Losses {'ner': 0.0006925182633050084}\n",
      "Losses {'ner': 4.533671075561507e-05}\n",
      "Losses {'ner': 0.00034858205621772834}\n",
      "Losses {'ner': 0.0006054032148068294}\n",
      "Losses {'ner': 9.847758364599013e-06}\n",
      "Losses {'ner': 6.537535654488151e-05}\n",
      "Losses {'ner': 0.14411271232623984}\n",
      "Losses {'ner': 3.979776723117825e-05}\n",
      "Losses {'ner': 8.810505287273175e-07}\n",
      "Losses {'ner': 0.0012582829601439582}\n",
      "Losses {'ner': 0.006535414601671394}\n",
      "Losses {'ner': 0.0016942731731422972}\n",
      "Losses {'ner': 1.199235013405366e-05}\n",
      "Losses {'ner': 0.0028229465066468944}\n",
      "Losses {'ner': 9.055559613301625e-08}\n",
      "Losses {'ner': 1.0783933689075199e-08}\n",
      "Losses {'ner': 5.910197450274439}\n",
      "Losses {'ner': 8.941065217077925e-05}\n",
      "Losses {'ner': 2.1755127125767813e-06}\n",
      "Losses {'ner': 3.644282454070148}\n",
      "Losses {'ner': 4.4519610011633415e-05}\n",
      "Losses {'ner': 3.464698101695122}\n",
      "Losses {'ner': 2.8728329046224255e-05}\n",
      "Losses {'ner': 4.993809420698579e-06}\n",
      "Losses {'ner': 0.004180670830591195}\n",
      "Losses {'ner': 1.029769673522446e-06}\n",
      "Losses {'ner': 3.0245018205652046e-05}\n",
      "Losses {'ner': 0.0002288241188847999}\n",
      "Losses {'ner': 1.7274626233430765e-07}\n",
      "Losses {'ner': 3.7326781003348e-07}\n",
      "Losses {'ner': 0.00014939720540772203}\n",
      "Losses {'ner': 2.875297961041756e-06}\n",
      "Losses {'ner': 0.001379526050884453}\n",
      "Losses {'ner': 2.4449727424887913e-06}\n",
      "Losses {'ner': 3.0765962310984134e-05}\n",
      "Losses {'ner': 0.27453866069318056}\n",
      "Losses {'ner': 8.339299799340222e-06}\n",
      "Losses {'ner': 2.017705289175275e-06}\n",
      "Losses {'ner': 2.1422600695537737}\n",
      "Losses {'ner': 0.00012837063544601774}\n",
      "Losses {'ner': 0.0003042036597868351}\n",
      "Entities [('Jeff Bezos', 'PERSON'), ('Amazon', 'ORG')]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import random\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "\n",
    "# Define the training data\n",
    "train_data = [\n",
    "    (\"Elon Musk is the CEO of SpaceX and Tesla.\", {\"entities\": [(0, 8, \"PERSON\"), (23, 28, \"ORG\"), (33, 38, \"ORG\")]}),\n",
    "    (\"Steve Jobs was the CEO of Apple.\", {\"entities\": [(0, 10, \"PERSON\"), (24, 29, \"ORG\")]}),\n",
    "    (\"Barack Obama was the 44th President of the United States.\", {\"entities\": [(0, 12, \"PERSON\"), (34, 50, \"GPE\")]}),\n",
    "    (\"Satya Nadella is the CEO of Microsoft.\", {\"entities\": [(0, 12, \"PERSON\"), (23, 33, \"ORG\")]}),\n",
    "    (\"Amazon is the world's largest online retailer.\", {\"entities\": [(0, 6, \"ORG\")]}),\n",
    "    (\"Mark Zuckerberg is the CEO of Facebook.\", {\"entities\": [(0, 14, \"PERSON\"), (23, 31, \"ORG\")]}),\n",
    "]\n",
    "\n",
    "# Define the function to train the model\n",
    "def train_model(train_data, iterations):\n",
    "\n",
    "    # Load the spaCy model with the path to the lookup tables\n",
    "    nlp = spacy.load(\"en_core_web_sm\", exclude=[\"parser\", \"ner\"], lookups=lookups_path)\n",
    "\n",
    "    if \"ner\" not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe(\"ner\")\n",
    "        nlp.add_pipe(ner, last=True)\n",
    "    else:\n",
    "        ner = nlp.get_pipe(\"ner\")\n",
    "\n",
    "    for _, annotations in train_data:\n",
    "        for ent in annotations.get(\"entities\"):\n",
    "            ner.add_label(ent[2])\n",
    "\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
    "    with nlp.disable_pipes(*other_pipes):\n",
    "        optimizer = nlp.begin_training()\n",
    "        for i in range(iterations):\n",
    "            random.shuffle(train_data)\n",
    "            losses = {}\n",
    "            batches = minibatch(train_data, size=compounding(4.0, 32.0, 1.001))\n",
    "            for batch in batches:\n",
    "                texts, annotations = zip(*batch)\n",
    "                nlp.update(texts, annotations, sgd=optimizer, drop=0.35, losses=losses)\n",
    "            print(\"Losses\", losses)\n",
    "    return nlp\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model = train_model(train_data, iterations=100)\n",
    "\n",
    "# Test the model\n",
    "text = \"Jeff Bezos is the founder of Amazon.\"\n",
    "doc = model(text)\n",
    "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9639b5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages\\numpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll\n",
      "C:\\Users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n",
      "C:\\Users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Use HuggingFace's datasets library to access the financial_phrasebank dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8cfe99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93e90dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset bionlp2004 (F:/ICRL/projects/55/Sentiment classification/data_cache/tner___bionlp2004/bionlp2004/1.0.0/9f41d3f0270b773c2762dee333ae36c29331e2216114a57081f77639fdb5e904)\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 500.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset is a dictionary with 3 splits: \n",
      "\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['tokens', 'tags'],\n",
      "        num_rows: 16619\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['tokens', 'tags'],\n",
      "        num_rows: 1927\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['tokens', 'tags'],\n",
      "        num_rows: 3856\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\n",
    "    \"tner/bionlp2004\", \n",
    "    cache_dir='./data_cache'\n",
    ")\n",
    "\n",
    "print(f'The dataset is a dictionary with {len(dataset)} splits: \\n\\n{dataset}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c1b0607",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences_ner = [item['tokens'] for item in dataset['train']]\n",
    "train_sentences = [' '.join(sentence) for sentence in train_sentences_ner]\n",
    "train_labels_ner = [[str(tag) for tag in item['tags']] for item in dataset['train']]\n",
    "\n",
    "val_sentences_ner = [item['tokens'] for item in dataset['validation']]\n",
    "val_sentences = [' '.join(sentence) for sentence in val_sentences_ner]\n",
    "val_labels_ner = [[str(tag) for tag in item['tags']] for item in dataset['validation']]\n",
    "\n",
    "test_sentences_ner = [item['tokens'] for item in dataset['test']]\n",
    "test_sentences = [' '.join(sentence) for sentence in test_sentences_ner]\n",
    "test_labels_ner = [[str(tag) for tag in item['tags']] for item in dataset['test']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1b41504",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd07781b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Since HUVECs released superoxide anions in response to TNF , and H2O2 induces VCAM-1 , PDTC may act as a radical scavenger .\n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "text = train_sentences\n",
    "doc = nlp(text[0])\n",
    "\n",
    "for sent in doc.sents:\n",
    "    print(sent)\n",
    "    corpus.append(sent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e99e422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Treblinka is a small village in Poland.', {'entities': [[32, 38, 'GPE']]}], ['Wikipedia notes that Treblinka is not large.', {'entities': [[0, 9, 'ORG']]}]]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "text = \"Treblinka is a small village in Poland. Wikipedia notes that Treblinka is not large.\"\n",
    "corpus = []\n",
    "\n",
    "doc = nlp(text)\n",
    "for sent in doc.sents:\n",
    "    corpus.append(sent.text)\n",
    "\n",
    "# nlp = spacy.blank(\"en\")\n",
    "\n",
    "# ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "\n",
    "# patterns = [\n",
    "#                 {\"label\": \"GPE\", \"pattern\": \"Treblinka\"}\n",
    "#             ]\n",
    "\n",
    "# ruler.add_patterns(patterns)\n",
    "\n",
    "TRAIN_DATA = []\n",
    "for sentence in corpus:\n",
    "    doc = nlp(sentence)\n",
    "    entities = []\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        entities.append([ent.start_char, ent.end_char, ent.label_])\n",
    "    TRAIN_DATA.append([sentence, {\"entities\": entities}])\n",
    "\n",
    "print (TRAIN_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b303f91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import DocBin\n",
    "\n",
    "def convert(lang: str, TRAIN_DATA, output_path):\n",
    "    nlp = spacy.blank(lang)\n",
    "    db = DocBin()\n",
    "    for text, annot in TRAIN_DATA:\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label)\n",
    "            if span is None:\n",
    "                msg = f\"Skipping entity [{start}, {end}, {label}] in the following text because the character span '{doc.text[start:end]}' does not align with token boundaries:\\n\\n{repr(text)}\\n\"\n",
    "                warnings.warn(msg)\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    db.to_disk(output_path)\n",
    "    \n",
    "convert(\"en\", TRAIN_DATA, \"train.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0025ab8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 11:54:56.481039: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2023-04-05 11:54:56.481085: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-04-05 11:54:59.741628: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'nvcuda.dll'; dlerror: nvcuda.dll not found\n",
      "2023-04-05 11:54:59.741654: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-04-05 11:54:59.744742: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: DESKTOP-38ONH9K\n",
      "2023-04-05 11:54:59.744815: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: DESKTOP-38ONH9K\n",
      "C:\\Users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages\\numpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll\n",
      "C:\\Users\\abdul\\anaconda3\\envs\\tf2x\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n",
      "Usage: python -m spacy init fill-config [OPTIONS] BASE_PATH [OUTPUT_FILE]\n",
      "Try 'python -m spacy init fill-config --help' for help.\n",
      "\n",
      "Error: Invalid value for 'BASE_PATH': File 'base_config.cfg' does not exist.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config base_config.cfg config.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f7219a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Since HUVECs released superoxide anions in response to TNF , and H2O2 induces VCAM-1 , PDTC may act as a radical scavenger .\n",
      "8\n",
      "9\n",
      "ORG\n",
      "11\n",
      "12\n",
      "ORG\n",
      "15\n",
      "16\n",
      "ORG\n"
     ]
    }
   ],
   "source": [
    "for sentence in corpus:\n",
    "    doc = nlp(sentence)\n",
    "    print(doc)\n",
    "    entities = []\n",
    "    TRAIN_DATA = []\n",
    "    for ent in doc.ents:\n",
    "        print(ent.start)\n",
    "        print(ent.end)\n",
    "        print(ent.label_)\n",
    "        entities.append([ent.start_char, ent.end_char, ent.label_])\n",
    "    TRAIN_DATA.append([sentence, {\"entities\": entities}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cc0123",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
